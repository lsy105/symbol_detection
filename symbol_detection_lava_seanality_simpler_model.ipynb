{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138b6027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "\n",
    "from Loss import ber_loss\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import slayer from lava-dl\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "import IPython.display as display\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.__version__\n",
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4) (7521, 4)\n",
      "test_input_diff:  tensor(4.3360e-10, dtype=torch.float64)\n",
      "train_input_diff:  tensor(4.2755e-11, dtype=torch.float64)\n",
      "train_label_diff:  tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [55]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "RC_test_input = np.load('gt_test_input_1.npy')\n",
    "RC_train_input = np.load('gt_train_input_1.npy')\n",
    "RC_train_label = np.load('gt_train_label_1.npy')\n",
    "\n",
    "print(RC_test_input.shape, test_input.shape)\n",
    "print(\"test_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_test_input), torch.tensor(test_input)))\n",
    "\n",
    "print(\"train_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_input), torch.tensor(train_input)))\n",
    "\n",
    "print(\"train_label_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_label), torch.tensor(train_label)))\n",
    "\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std\n",
    "train_label = 1.0 * train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a8c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4)\n",
      "(7521, 4)\n",
      "(7521, 2)\n",
      "(89, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7395dfe-dc16-458e-989e-b39bfcc397e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4\n",
      "0  0.004551  0.004551 -1.889301  0.270783\n",
      "1 -1.889301  0.270783  0.812164 -5.135720\n",
      "2  0.812164 -5.135720  2.438245  1.358288\n",
      "3  2.438245  1.358288  0.273331  5.137965\n",
      "4  0.273331  5.137965  0.011841  3.786904\n",
      "             1         2         3         4\n",
      "6001 -0.661122  0.675264 -0.210914 -1.233754\n",
      "6002 -0.210914 -1.233754 -0.928992 -0.693273\n",
      "6003 -0.928992 -0.693273 -1.298579  0.323413\n",
      "6004 -1.298579  0.323413  0.260540 -0.842280\n",
      "6005  0.260540 -0.842280  0.518144  0.138121\n",
      "(6001, 4)\n",
      "(1520, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def pre_processing(train_input, train_label):\n",
    "    idx_p = 10\n",
    "    begin = 0 # N_total_frame * N_sync_frame\n",
    "    \n",
    "    # label index for data\n",
    "    train_input_df = pd.DataFrame(train_input, columns = ['1','2', '3', '4'])\n",
    "    #train_input_df['L1_idx'] = train_input_df.index % idx_p\n",
    "\n",
    "    # label index for label\n",
    "    train_label_df = pd.DataFrame(train_label, columns = ['L1','L2'])\n",
    "    train_label_df['L1_idx'] = train_label_df.index % idx_p\n",
    "    \n",
    "    # split training and testing data\n",
    "    test_input_df, test_label_df = train_input_df.iloc[75* 80 + 1:, :], train_label_df.iloc[75* 80 + 1:, :]\n",
    "    train_input_df, train_label_df = train_input_df.iloc[:75* 80 + 1, :], train_label_df.iloc[:75* 80 + 1, :]\n",
    "\n",
    "    # group by \n",
    "    #mapping = train_label_df.loc[begin:, :].groupby(by='L1_idx').mean().reset_index().loc[:, ['L1', 'L2', 'L1_idx']] \n",
    "    \n",
    "    #train_input_df = pd.merge(train_input_df, mapping, how='left', on='L1_idx')\n",
    "\n",
    "    #train_input_df = pd.get_dummies(train_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    train_input_df = train_input_df.loc[begin:, :]\n",
    "\n",
    "\n",
    "    print(train_input_df.head())\n",
    "    \n",
    "    # testing data\n",
    "    # group by\n",
    "    #test_input_df = test_input_df.merge(mapping, how = 'left', on='L1_idx')\n",
    "\n",
    "    #test_input_df = pd.get_dummies(test_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    print(test_input_df.head())\n",
    "\n",
    "    train_input = train_input_df.to_numpy()\n",
    "    test_input = test_input_df.to_numpy()\n",
    "    \n",
    "    train_label = train_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    test_label = test_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    \n",
    "    print(train_input.shape)\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    \n",
    "    return train_input, train_label, test_input, test_label\n",
    "\n",
    "train_input, train_label, test_input, test_label = pre_processing(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acdc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n",
      "(24, 100)\n",
      "(1,)\n",
      "(24,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 6\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, RegTorchSeasonalitySpikingDataset, RegSpikingDataset, RegTorchSpikingDataset, RegTorchSeasonalityLinearSpikingDataset\n",
    "train_data = RegTorchSeasonalityLinearSpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "test_data = RegTorchSeasonalityLinearSpikingDataset(test_input, test_label, nb_inputs, nb_steps)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "       # neuron_params = {\n",
    "       #         'threshold'     : 0.1,\n",
    "       #         'current_decay' : 1,\n",
    "       #         'voltage_decay' : 0.1,\n",
    "       #         'requires_grad' : True,     \n",
    "       #     }\n",
    "        #neuron_params_drop = {**neuron_params, 'dropout' : slayer.neuron.Dropout(p=0.05),}\n",
    "        neuron_params = {\n",
    "                'threshold'     : 1.25,\n",
    "                'current_decay' : 0.25,\n",
    "                'voltage_decay' : 0.03,\n",
    "                'tau_grad'      : 0.03,\n",
    "                'scale_grad'    : 100,\n",
    "                'requires_grad' : True,     \n",
    "            }\n",
    "        \n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "                #slayer.block.cuba.Input(neuron_params),\n",
    "                slayer.block.cuba.Dense(neuron_params, input_size, 8, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Recurrent(neuron_params, input_size, 8, weight_norm=True, delay=True),\n",
    "                slayer.block.cuba.Dense(neuron_params, 8, 1, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 64, 128, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 128, output_size, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, input_size, 64, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 64, 128, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 128, output_size, weight_scale=2, weight_norm=True)\n",
    "                #slayer.block.cuba.Recurrent(cuba_params, 100, 50),\n",
    "                #slayer.block.cuba.KWTA(cuba_params, 50, 50, num_winners=5)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, spike):\n",
    "        for block in self.blocks:\n",
    "            spike = block(spike)\n",
    "        return spike\n",
    "\n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "\n",
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2)\n",
    "        self.fc2 = nn.Linear(16 + 1 + 24, 8)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "        #self.fc3 = nn.Linear(128, 128)\n",
    "        #self.fc4 = nn.Linear(128, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x, x1, x2):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = torch.cat((x, x2), axis=1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc3(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1084390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.neuron.current_decay torch.Size([1])\n",
      "blocks.0.neuron.voltage_decay torch.Size([1])\n",
      "blocks.0.delay.delay torch.Size([1])\n",
      "blocks.0.synapse.weight_g torch.Size([8, 1, 1, 1, 1])\n",
      "blocks.0.synapse.weight_v torch.Size([8, 24, 1, 1, 1])\n",
      "blocks.1.neuron.current_decay torch.Size([1])\n",
      "blocks.1.neuron.voltage_decay torch.Size([1])\n",
      "blocks.1.delay.delay torch.Size([1])\n",
      "blocks.1.synapse.weight_g torch.Size([1, 1, 1, 1, 1])\n",
      "blocks.1.synapse.weight_v torch.Size([1, 8, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "net_snn = Network(nb_inputs * 4, 2).to(device)\n",
    "net_dnn = DNNNetwork(1 * 100 + nb_inputs * 4 + 0 + 0 * nb_inputs, 2).to(device)\n",
    "\n",
    "for name, weight in net_snn.named_parameters():\n",
    "    print(name, weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8441bd-8c48-4451-a52d-88763313aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147/3983635306.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_147/3983635306.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_147/3983635306.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_147/3983635306.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.2960, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.3084, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.2835, dtype=torch.float64)\n",
      "percent loss:  13094.359336457554\n",
      "testing ber:  0.518640350877193\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader, net_snn, net_dnn, rc, num_frame = 19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        \n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    print(\"testing MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    print(\"testing MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    print(\"testing MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    print(\"percent loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing ber: \", rc.my_new_test(predict_time, target_time))\n",
    "\n",
    "test(test_loader, net_snn, net_dnn, rc, num_frame=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce4a5c2-38de-466c-ab45-ae78ecfc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(output, target):\n",
    "    #loss = (output - target) ** 2 / (target ** 2 + 1e-6)\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def train(trainloader, testloader, model, DNN_model, rc, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    params = list(model.parameters()) + list(DNN_model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    #loss_fn = ber_loss\n",
    "    loss_hist = []\n",
    "    DNN_model.train()\n",
    "    \n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        local_loss = []\n",
    "        for x_local, x1_local, x2_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            #output = model(x_local)\n",
    "            #output = output.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_local)\n",
    "            output = DNN_model(output, x1_local, x2_local)\n",
    "            loss_val = loss_fn(output, y_local) \n",
    "            loss_val.backward()\n",
    "            #print(\"AAAA: \", DNN_model.fc2.weight)\n",
    "            #print(\"BBBB: \", DNN_model.fc1.weight.grad)\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "            \n",
    "        \n",
    "        #if e % 1 == 30 and e != 0:\n",
    "        #    print(\"Training accuracy: %.3f\"%(compute_ber(trainloader, net, \"train\")))\n",
    "        #    print(\"Test accuracy: %.3f\"%(compute_ber(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(mean_loss)\n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        #test(testloader, model, DNN_model)\n",
    "        #test_train(trainloader, model, DNN_model)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f574380-3878-4cbd-9a38-19da46e5efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.22657849481131168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147/3983635306.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_147/3983635306.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_147/3983635306.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_147/3983635306.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0315, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0462, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0167, dtype=torch.float64)\n",
      "percent loss:  2952.681330343785\n",
      "testing ber:  0.4095394736842105\n",
      "1\n",
      "0.1051312194384159\n",
      "testing MSE:  tensor(0.0078, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0074, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0082, dtype=torch.float64)\n",
      "percent loss:  1174.0686461543535\n",
      "testing ber:  0.3059210526315789\n",
      "2\n",
      "0.062413494261179835\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1088.442290149031\n",
      "testing ber:  0.14528508771929824\n",
      "3\n",
      "0.04031800167595453\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1256.5705109406388\n",
      "testing ber:  0.17489035087719298\n",
      "4\n",
      "0.03530946988216106\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1427.9940724913347\n",
      "testing ber:  0.16392543859649122\n",
      "5\n",
      "0.03510486392026886\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1427.7199256752556\n",
      "testing ber:  0.15515350877192982\n",
      "6\n",
      "0.036097536180564695\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1562.2000603437577\n",
      "testing ber:  0.16611842105263158\n",
      "7\n",
      "0.03509492518261392\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1573.353272013849\n",
      "testing ber:  0.15460526315789475\n",
      "8\n",
      "0.03517361805635564\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1689.6785294587203\n",
      "testing ber:  0.14912280701754385\n",
      "9\n",
      "0.03494236883806422\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1675.8871016655849\n",
      "testing ber:  0.15515350877192982\n",
      "10\n",
      "0.035249649963163314\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1723.6072818480707\n",
      "testing ber:  0.14857456140350878\n",
      "11\n",
      "0.03518308467291137\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1718.5516431563356\n",
      "testing ber:  0.1513157894736842\n",
      "12\n",
      "0.03522600037382638\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1732.900260526546\n",
      "testing ber:  0.14364035087719298\n",
      "13\n",
      "0.03558753839040056\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1720.5885527869202\n",
      "testing ber:  0.14089912280701755\n",
      "14\n",
      "0.03553875072046797\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1712.8419568193788\n",
      "testing ber:  0.13322368421052633\n",
      "15\n",
      "0.03559362291893427\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1717.8394601567213\n",
      "testing ber:  0.13103070175438597\n",
      "16\n",
      "0.035643605317207096\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1682.0195298273566\n",
      "testing ber:  0.13486842105263158\n",
      "17\n",
      "0.03587116762757935\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1686.2689056659178\n",
      "testing ber:  0.14035087719298245\n",
      "18\n",
      "0.035714343527054535\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1678.9574567494483\n",
      "testing ber:  0.14089912280701755\n",
      "19\n",
      "0.03562245274240032\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1660.0945811637143\n",
      "testing ber:  0.1513157894736842\n",
      "20\n",
      "0.035427339038157715\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1638.8017349809047\n",
      "testing ber:  0.125\n",
      "21\n",
      "0.03511541824233025\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1655.4920713568615\n",
      "testing ber:  0.13157894736842105\n",
      "22\n",
      "0.035514759514084525\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1660.8435878523792\n",
      "testing ber:  0.1337719298245614\n",
      "23\n",
      "0.03493543644931088\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1618.190437002297\n",
      "testing ber:  0.13541666666666666\n",
      "24\n",
      "0.03528568289302131\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1582.041783073498\n",
      "testing ber:  0.12171052631578948\n",
      "25\n",
      "0.0349380857251743\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1581.123300848288\n",
      "testing ber:  0.11403508771929824\n",
      "26\n",
      "0.03593514990457829\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1574.5275441544768\n",
      "testing ber:  0.10635964912280702\n",
      "27\n",
      "0.03493669256567955\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1558.8664229551187\n",
      "testing ber:  0.10416666666666667\n",
      "28\n",
      "0.03492665298758669\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1589.6764302818533\n",
      "testing ber:  0.125\n",
      "29\n",
      "0.03461188321655735\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1578.329011723855\n",
      "testing ber:  0.12390350877192982\n",
      "30\n",
      "0.03550207515821812\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1510.707028671199\n",
      "testing ber:  0.09868421052631579\n",
      "31\n",
      "0.03480195771268708\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1537.5037156600604\n",
      "testing ber:  0.1206140350877193\n",
      "32\n",
      "0.034653927001388786\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1568.4267849945975\n",
      "testing ber:  0.12828947368421054\n",
      "33\n",
      "0.03446371841462369\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1535.826964805706\n",
      "testing ber:  0.12116228070175439\n",
      "34\n",
      "0.0345747830306596\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1568.92585608823\n",
      "testing ber:  0.1288377192982456\n",
      "35\n",
      "0.0347177498438891\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1514.6389513922295\n",
      "testing ber:  0.14583333333333334\n",
      "36\n",
      "0.034433585908660226\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1488.6090547550339\n",
      "testing ber:  0.10307017543859649\n",
      "37\n",
      "0.03433438661964016\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1533.7369739975748\n",
      "testing ber:  0.12938596491228072\n",
      "38\n",
      "0.03391498662135069\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1618.4618844489532\n",
      "testing ber:  0.13486842105263158\n",
      "39\n",
      "0.03346183323400452\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1463.0373964709854\n",
      "testing ber:  0.09923245614035088\n",
      "40\n",
      "0.03362510737745052\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1461.5769418972127\n",
      "testing ber:  0.13815789473684212\n",
      "41\n",
      "0.03315689178936659\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1419.5276213984894\n",
      "testing ber:  0.11732456140350878\n",
      "42\n",
      "0.03312211075520262\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1470.3023056355764\n",
      "testing ber:  0.0893640350877193\n",
      "43\n",
      "0.03321282969827347\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1496.8836812819595\n",
      "testing ber:  0.09868421052631579\n",
      "44\n",
      "0.03295660863055828\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1428.2255680775625\n",
      "testing ber:  0.12445175438596491\n",
      "45\n",
      "0.03260339148580394\n",
      "testing MSE:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0028, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0025, dtype=torch.float64)\n",
      "percent loss:  1416.0344185836332\n",
      "testing ber:  0.15899122807017543\n",
      "46\n",
      "0.032671917606382925\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1390.8269911601294\n",
      "testing ber:  0.1112938596491228\n",
      "47\n",
      "0.03288408563016577\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1439.8043379279898\n",
      "testing ber:  0.12774122807017543\n",
      "48\n",
      "0.032657625649045126\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1381.0230950946088\n",
      "testing ber:  0.13048245614035087\n",
      "49\n",
      "0.03262150529375736\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  1359.1740326489462\n",
      "testing ber:  0.13432017543859648\n",
      "50\n",
      "0.03202247050927674\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1304.3065568359564\n",
      "testing ber:  0.11732456140350878\n",
      "51\n",
      "0.03260463640648634\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1371.1935865877028\n",
      "testing ber:  0.11732456140350878\n",
      "52\n",
      "0.03246942281405976\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1348.9381007792826\n",
      "testing ber:  0.0981359649122807\n",
      "53\n",
      "0.03246030346193212\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1387.9419270169694\n",
      "testing ber:  0.14309210526315788\n",
      "54\n",
      "0.03234553386635603\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1327.7934783618352\n",
      "testing ber:  0.11842105263157894\n",
      "55\n",
      "0.03311715641633627\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1433.5633561739878\n",
      "testing ber:  0.11787280701754387\n",
      "56\n",
      "0.031991404124555436\n",
      "testing MSE:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1386.5317567294971\n",
      "testing ber:  0.14364035087719298\n",
      "57\n",
      "0.0322558263396012\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1312.274085751849\n",
      "testing ber:  0.10032894736842106\n",
      "58\n",
      "0.03251231838255487\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1554.3306110734852\n",
      "testing ber:  0.14144736842105263\n",
      "59\n",
      "0.03201161061433402\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1266.3739018664542\n",
      "testing ber:  0.10855263157894737\n",
      "60\n",
      "0.03246518598988335\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1468.4183387366306\n",
      "testing ber:  0.12828947368421054\n",
      "61\n",
      "0.03206001275635146\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1279.4547019886754\n",
      "testing ber:  0.10087719298245613\n",
      "62\n",
      "0.03337191711080835\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1465.9289018563213\n",
      "testing ber:  0.11074561403508772\n",
      "63\n",
      "0.03184725318421075\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1326.863659447798\n",
      "testing ber:  0.10855263157894737\n",
      "64\n",
      "0.03218309670448937\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1284.4304282438773\n",
      "testing ber:  0.125\n",
      "65\n",
      "0.031762345872343854\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1412.2633685290928\n",
      "testing ber:  0.13651315789473684\n",
      "66\n",
      "0.03178739062252831\n",
      "testing MSE:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0029, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1326.3676145804877\n",
      "testing ber:  0.1524122807017544\n",
      "67\n",
      "0.03166357057287972\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1406.4868552065323\n",
      "testing ber:  0.13048245614035087\n",
      "68\n",
      "0.03189618081012939\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1449.1725280321932\n",
      "testing ber:  0.12445175438596491\n",
      "69\n",
      "0.03235518411198195\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1392.1107487974564\n",
      "testing ber:  0.13651315789473684\n",
      "70\n",
      "0.03171599077734542\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1323.6340187873848\n",
      "testing ber:  0.11458333333333333\n",
      "71\n",
      "0.03203536772188988\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1269.2867750511234\n",
      "testing ber:  0.10471491228070176\n",
      "72\n",
      "0.03162824005839673\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1268.8880331535754\n",
      "testing ber:  0.10855263157894737\n",
      "73\n",
      "0.0321157204106133\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1257.8145254888589\n",
      "testing ber:  0.10910087719298246\n",
      "74\n",
      "0.03156961140004878\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1343.3559830304787\n",
      "testing ber:  0.1288377192982456\n",
      "75\n",
      "0.03190241486547475\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1252.0817835844555\n",
      "testing ber:  0.10471491228070176\n",
      "76\n",
      "0.03240377148811487\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1355.6689594471638\n",
      "testing ber:  0.10526315789473684\n",
      "77\n",
      "0.03189178845508302\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1262.203748873792\n",
      "testing ber:  0.09703947368421052\n",
      "78\n",
      "0.03209702185097527\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1576.9020877457965\n",
      "testing ber:  0.13760964912280702\n",
      "79\n",
      "0.031930136969907486\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1186.638530537281\n",
      "testing ber:  0.09649122807017543\n",
      "80\n",
      "0.033072984618867964\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1310.6422522420962\n",
      "testing ber:  0.09539473684210527\n",
      "81\n",
      "0.03261514675823298\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1379.4521273757484\n",
      "testing ber:  0.10197368421052631\n",
      "82\n",
      "0.03221073393967557\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1518.9125183993017\n",
      "testing ber:  0.14802631578947367\n",
      "83\n",
      "0.03233092983669423\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1274.3300886615232\n",
      "testing ber:  0.09649122807017543\n",
      "84\n",
      "0.03288050705289587\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1349.6452315472666\n",
      "testing ber:  0.09375\n",
      "85\n",
      "0.03219314309907086\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1440.3807204638895\n",
      "testing ber:  0.11567982456140351\n",
      "86\n",
      "0.032373968392927596\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1229.4313866790703\n",
      "testing ber:  0.09923245614035088\n",
      "87\n",
      "0.03289616751940327\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1390.3970928399774\n",
      "testing ber:  0.10032894736842106\n",
      "88\n",
      "0.03149664641774081\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1365.720055999097\n",
      "testing ber:  0.10526315789473684\n",
      "89\n",
      "0.03215903937420313\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1523.2469008385024\n",
      "testing ber:  0.15296052631578946\n",
      "90\n",
      "0.03187155188556681\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1221.213843092737\n",
      "testing ber:  0.09320175438596491\n",
      "91\n",
      "0.032499227771892195\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1406.7956503256553\n",
      "testing ber:  0.13596491228070176\n",
      "92\n",
      "0.031836876348453634\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0010, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1219.7734197751597\n",
      "testing ber:  0.09703947368421052\n",
      "93\n",
      "0.033047456452821165\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1330.7940253521454\n",
      "testing ber:  0.09758771929824561\n",
      "94\n",
      "0.03162106021525378\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1324.8467452497305\n",
      "testing ber:  0.10581140350877193\n",
      "95\n",
      "0.0321240273324099\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1376.4322108521021\n",
      "testing ber:  0.12390350877192982\n",
      "96\n",
      "0.03129928097366653\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1263.3388948036195\n",
      "testing ber:  0.0981359649122807\n",
      "97\n",
      "0.03131108122699438\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1244.1798300493401\n",
      "testing ber:  0.10964912280701754\n",
      "98\n",
      "0.0315307608230951\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1324.768696814239\n",
      "testing ber:  0.13980263157894737\n",
      "99\n",
      "0.0318113782225137\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0010, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1230.5583825028436\n",
      "testing ber:  0.10307017543859649\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, net_snn, net_dnn, rc, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac761138-0e7d-42b0-a0ed-c75ab87036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219/3403701246.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_219/3403701246.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_219/3403701246.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_219/3403701246.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE RC:  tensor(0.0051, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0036, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "RC_train_time = np.load(\"gt_train_pred.npy\")\n",
    "print(\"train MSE: \", torch.nn.MSELoss()(torch.tensor(RC_train_time), torch.tensor(train_label)))\n",
    "def test_train_both(train_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in train_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    print(\"train MSE RC: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(RC_train_time)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(train_label)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(train_label), torch.tensor(RC_train_time)))\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_train_both(train_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808d7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_snn.export_hdf5('./net_snn.net')\n",
    "torch.save(net_dnn.state_dict(), './net_dnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "898cb37e-9af7-45f8-a3e2-8ddbd0db0dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/229205384.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/229205384.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/229205384.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/229205384.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7521, 2]) torch.Size([7521, 2])\n",
      "all_loss:  tensor(0.0024)\n",
      "no first 330 loss:  tensor(0.0014)\n"
     ]
    }
   ],
   "source": [
    "temp_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test_MSE(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "    \n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "    \n",
    "    all_output = torch.tensor(np.concatenate(all_output, axis=0)).detach()\n",
    "    labels = torch.tensor(np.concatenate(labels, axis=0)).detach()\n",
    "    print(all_output.shape, labels.shape)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    print(\"all_loss: \", loss_fn(all_output, labels))\n",
    "    print(\"no first 330 loss: \", loss_fn(all_output[330:, :], labels[330:, :]))\n",
    "\n",
    "test_MSE(temp_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7acff8c-50b2-4bd2-93f8-b3106dddedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/3202473027.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/3202473027.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/3202473027.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/3202473027.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18902153558052434\n"
     ]
    }
   ],
   "source": [
    "all_output = []\n",
    "inputs = []\n",
    "labels = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    ber = rc.my_test(all_output)\n",
    "    print(ber)\n",
    "    \n",
    "test(test_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ee219a-952a-4395-b2a9-db85d18f17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        ...,\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "A1 = 8 * torch.ones((128, 8))\n",
    "A2 = torch.ones((128, 1))\n",
    "print(A1 + A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eebf40-ab07-4dda-9afb-3caa814cefa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
