{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31d6c99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import typing as ty\n",
    "import lava\n",
    "\n",
    "# Import Process level primitives\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "\n",
    "# Import MNIST dataset\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense  \n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194628c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [1000]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S2'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23c\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc5e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 2\n",
    "num_input_node = 4\n",
    "num_steps = 100\n",
    "train_data = RegSpikingDataset(train_input, train_label, sequence_length, num_steps)\n",
    "dataset = []\n",
    "for i in range(len(train_data)):\n",
    "    dataset.append(train_data[i][0].reshape((num_steps, -1)).astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b77d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('outfile', 'wb') as fp:\n",
    "    pickle.dump(dataset, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbba2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantization(path):\n",
    "    weights = []\n",
    "    f = open(path, 'rb')\n",
    "    mask1 = np.load(f)\n",
    "    mask2 = np.load(f)\n",
    "    weight1 = np.load(f)\n",
    "    weights.append(mask1)\n",
    "    weights.append(mask2)\n",
    "    weights.append(weight1)\n",
    "    f.close()\n",
    "\n",
    "    print(mask1.shape, mask2.shape, weight1.shape)\n",
    "\n",
    "    # Quantize weights and biases using max-normalization (Strong quantization loss if distributions have large tails)\n",
    "    from nxsdk_modules_ncl.dnn.src.utils import to_integer\n",
    "    p_int = []\n",
    "    Vth, int_w = [], []\n",
    "\n",
    "    for w in weights:\n",
    "        #length = np.n([np.abs(np.min(w)), np.abs(np.max(w))])\n",
    "        print(np.min(w), np.max(w))\n",
    "        length = np.max([np.abs(np.min(w)), np.abs(np.max(w))])\n",
    "        print(np.round(255.0/length))\n",
    "        Vth.append(np.round(255.0/length))\n",
    "        b = np.zeros(w.shape[0])\n",
    "        w_int, b_int = to_integer(w, b, 8)\n",
    "\n",
    "        int_w.append(w_int)\n",
    "\n",
    "    return int_w, Vth\n",
    "\n",
    "\n",
    "class SpikeInput(AbstractProcess):\n",
    "    \"\"\"Reads image data from the MNIST dataset and converts it to spikes.\n",
    "    The resulting spike rate is proportional to the pixel value.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 sequence_length : ty.Optional[int] = 2,\n",
    "                 num_input_node : ty.Optional[int] = 4,\n",
    "                 num_steps: ty.Optional[int] = 100):\n",
    "        super().__init__()\n",
    "        self.sequence_length = Var(shape=(1,), init=sequence_length)\n",
    "        self.num_input_node = Var(shape=(1,), init=num_input_node) \n",
    "        shape = (sequence_length * num_input_node,)\n",
    "        self.spikes_out = OutPort(shape=shape)\n",
    "        self.num_steps = Var(shape=(1,), init=num_steps)\n",
    "        self.input_data = Var(shape=shape)\n",
    "            \n",
    "        \n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    input_data: np.ndarray = LavaPyType(np.ndarray, bool, precision=1)\n",
    "    num_steps: int = LavaPyType(int, int, precision=32)\n",
    "    sequence_length: int = LavaPyType(int, int, precision=32)\n",
    "    num_input_node: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.dataset = dataset\n",
    "        self.curr_id = 0\n",
    "        from collections import defaultdict\n",
    "        self.mp = defaultdict(int)\n",
    "        self.cnt = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % 1 == 0:\n",
    "            return True\n",
    "        return False\n",
    "        #return True\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        # time_step start with 1\n",
    "        curr_idx = (self.time_step - 1) // self.num_steps\n",
    "        cur_time_step = (self.time_step - 1) % self.num_steps\n",
    "        self.input_data = self.dataset[self.curr_id][cur_time_step, :]\n",
    "    \n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        print(self.input_data)\n",
    "        self.spikes_out.send(self.input_data)\n",
    "        #print(self.time_step)\n",
    "        #print(self.input_data)\n",
    "        #print(self.dataset[self.curr_id][(self.time_step - 1) % (self.num_steps)])\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a95e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adsfdasf 50\n",
      "cur_idx 0\n",
      "[False False False False False False False False]\n",
      "[ True  True False  True False  True  True False]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[ True  True  True False False  True  True False]\n",
      "[ True False False  True False  True  True False]\n",
      "[False False  True  True False  True False  True]\n",
      "[False  True  True False False False False False]\n",
      "[False False False False False  True  True  True]\n",
      "[ True False  True False  True  True False  True]\n",
      "[ True False  True False  True  True  True  True]\n",
      "[False  True False False False  True  True False]\n",
      "[False  True  True False  True False  True False]\n",
      "[False  True  True False False  True False  True]\n",
      "[ True  True  True  True False  True False  True]\n",
      "[False False False False  True  True  True False]\n",
      "[ True  True False  True  True  True False  True]\n",
      "[ True  True False  True  True False False  True]\n",
      "[False  True  True False  True  True  True  True]\n",
      "[False False False  True  True False False False]\n",
      "[False  True  True False False  True  True False]\n",
      "[ True  True  True  True False  True False False]\n",
      "[ True False False  True  True  True  True  True]\n",
      "[ True  True  True False False False  True False]\n",
      "[False  True  True False  True  True  True False]\n",
      "[ True False False False False False False False]\n",
      "[False False False False  True  True  True False]\n",
      "[ True False False False False False False False]\n",
      "[False  True  True False False  True False  True]\n",
      "[False  True False  True  True False  True False]\n",
      "[ True  True False  True  True  True False  True]\n",
      "[False False False  True  True False False False]\n",
      "[ True False  True False False False False  True]\n",
      "[False  True  True  True  True False False  True]\n",
      "[ True False False False False  True False False]\n",
      "[ True  True  True  True  True False False  True]\n",
      "[False  True False False False  True  True  True]\n",
      "[False  True  True False  True False  True False]\n",
      "[ True  True  True False False  True  True  True]\n",
      "[ True False False False False  True  True False]\n",
      "[False False  True False  True  True False  True]\n",
      "[ True False False  True  True  True  True  True]\n",
      "[False False  True  True False False False  True]\n",
      "[ True  True  True False  True False False  True]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[False  True  True False  True False False False]\n",
      "[False False  True  True False False False  True]\n",
      "[False  True  True  True  True  True False False]\n",
      "[ True False  True  True  True  True  True False]\n",
      "[False False False  True False False  True  True]\n",
      "[False False False False False False False False]\n",
      "[False False False False False False  True  True]\n",
      "[False  True  True False  True False False  True]\n",
      "[ True  True  True False  True  True  True  True]\n",
      "[False  True False  True  True  True  True  True]\n",
      "[ True False  True  True False  True  True False]\n",
      "[ True False False  True  True False  True False]\n",
      "[False  True  True  True False False  True  True]\n",
      "[False False  True  True  True False  True False]\n",
      "[False False False False False  True False False]\n",
      "[False  True  True  True False  True False  True]\n",
      "[False False False  True  True  True  True  True]\n",
      "[ True False False  True  True  True  True False]\n",
      "[False False  True  True False False  True  True]\n",
      "[ True False False  True False False  True  True]\n",
      "[ True False  True False False  True  True  True]\n",
      "[ True False False False  True  True  True  True]\n",
      "[False False  True  True  True False  True False]\n",
      "[False  True  True False  True  True  True False]\n",
      "[ True False False False False  True  True False]\n",
      "[False  True False False False  True False False]\n",
      "[ True  True False  True False  True False  True]\n",
      "[False  True False  True False  True False  True]\n",
      "[ True False False  True False False  True False]\n",
      "[ True  True False False False  True False False]\n",
      "[ True False False  True  True  True  True False]\n",
      "[False False False False False  True False  True]\n",
      "[ True False  True False False False False  True]\n",
      "[ True False False  True False False False False]\n",
      "[ True  True  True  True False False  True  True]\n",
      "[False False False False False  True False False]\n",
      "[ True False False False False  True  True False]\n",
      "[False False False False False  True  True False]\n",
      "[ True False False False False  True False False]\n",
      "[ True  True False False  True  True  True  True]\n",
      "[False False False  True  True False False False]\n",
      "[ True False  True False  True False False False]\n",
      "[False False False False  True False False  True]\n",
      "[False  True  True False False  True False  True]\n",
      "[ True False False  True  True  True False  True]\n",
      "[ True False False  True  True False False  True]\n",
      "[False False  True False False  True False  True]\n",
      "[False  True  True  True  True False False  True]\n",
      "[ True  True False  True False  True False  True]\n",
      "[ True  True False False  True False  True False]\n",
      "[ True False  True  True  True False False  True]\n",
      "[False  True False  True False  True  True  True]\n",
      "[ True False False  True  True False False False]\n",
      "[False  True  True  True  True  True  True False]\n",
      "[ True False  True  True False  True  True False]\n",
      "[ True False False  True False  True False False]\n",
      "[ True  True False  True False  True  True False]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[ True  True  True False False  True  True False]\n",
      "[ True False False  True False  True  True False]\n",
      "[False False  True  True False  True False  True]\n",
      "[False  True  True False False False False False]\n",
      "[False False False False False  True  True  True]\n",
      "[ True False  True False  True  True False  True]\n",
      "[ True False  True False  True  True  True  True]\n",
      "[False  True False False False  True  True False]\n",
      "[False  True  True False  True False  True False]\n",
      "[False  True  True False False  True False  True]\n",
      "[ True  True  True  True False  True False  True]\n",
      "[False False False False  True  True  True False]\n",
      "[ True  True False  True  True  True False  True]\n",
      "[ True  True False  True  True False False  True]\n",
      "[False  True  True False  True  True  True  True]\n",
      "[False False False  True  True False False False]\n",
      "[False  True  True False False  True  True False]\n",
      "[ True  True  True  True False  True False False]\n",
      "[ True False False  True  True  True  True  True]\n",
      "[ True  True  True False False False  True False]\n",
      "[False  True  True False  True  True  True False]\n",
      "[ True False False False False False False False]\n",
      "[False False False False  True  True  True False]\n",
      "[ True False False False False False False False]\n",
      "[False  True  True False False  True False  True]\n",
      "[False  True False  True  True False  True False]\n",
      "[ True  True False  True  True  True False  True]\n",
      "[False False False  True  True False False False]\n",
      "[ True False  True False False False False  True]\n",
      "[False  True  True  True  True False False  True]\n",
      "[ True False False False False  True False False]\n",
      "[ True  True  True  True  True False False  True]\n",
      "[False  True False False False  True  True  True]\n",
      "[False  True  True False  True False  True False]\n",
      "[ True  True  True False False  True  True  True]\n",
      "[ True False False False False  True  True False]\n",
      "[False False  True False  True  True False  True]\n",
      "[ True False False  True  True  True  True  True]\n",
      "[False False  True  True False False False  True]\n",
      "[ True  True  True False  True False False  True]\n",
      "[ True  True False  True  True False  True  True]\n",
      "[False  True  True False  True False False False]\n",
      "[False False  True  True False False False  True]\n",
      "[False  True  True  True  True  True False False]\n",
      "[ True False  True  True  True  True  True False]\n",
      "[False False False  True False False  True  True]\n",
      "[False False False False False False False False]\n",
      "[False False False False False False  True  True]\n",
      "[False  True  True False  True False False  True]\n",
      "[ True  True  True False  True  True  True  True]\n",
      "[False  True False  True  True  True  True  True]\n",
      "[ True False  True  True False  True  True False]\n",
      "[ True False False  True  True False  True False]\n",
      "[False  True  True  True False False  True  True]\n",
      "(8,)\n",
      "cur_idx 1\n",
      "[False False  True  True  True False  True False]\n",
      "[False False False False False  True False False]\n",
      "[False  True  True  True False  True False  True]\n",
      "[False False False  True  True  True  True  True]\n",
      "[ True False False  True  True  True  True False]\n",
      "[False False  True  True False False  True  True]\n",
      "[ True False False  True False False  True  True]\n",
      "[ True False  True False False  True  True  True]\n",
      "[ True False False False  True  True  True  True]\n",
      "[False False  True  True  True False  True False]\n",
      "[False  True  True False  True  True  True False]\n",
      "[ True False False False False  True  True False]\n",
      "[False  True False False False  True False False]\n",
      "[ True  True False  True False  True False  True]\n",
      "[False  True False  True False  True False  True]\n",
      "[ True False False  True False False  True False]\n",
      "[ True  True False False False  True False False]\n",
      "[ True False False  True  True  True  True False]\n",
      "[False False False False False  True False  True]\n",
      "[ True False  True False False False False  True]\n",
      "[ True False False  True False False False False]\n",
      "[ True  True  True  True False False  True  True]\n",
      "[False False False False False  True False False]\n",
      "[ True False False False False  True  True False]\n",
      "[False False False False False  True  True False]\n",
      "[ True False False False False  True False False]\n",
      "[ True  True False False  True  True  True  True]\n",
      "[False False False  True  True False False False]\n",
      "[ True False  True False  True False False False]\n",
      "[False False False False  True False False  True]\n",
      "[False  True  True False False  True False  True]\n",
      "[ True False False  True  True  True False  True]\n",
      "[ True False False  True  True False False  True]\n",
      "[False False  True False False  True False  True]\n",
      "[False  True  True  True  True False False  True]\n",
      "[ True  True False  True False  True False  True]\n",
      "[ True  True False False  True False  True False]\n",
      "[ True False  True  True  True False False  True]\n",
      "[False  True False  True False  True  True  True]\n",
      "[ True False False  True  True False False False]\n",
      "[False  True  True  True  True  True  True False]\n",
      "[ True False  True  True False  True  True False]\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "\n",
    "sequence_length = 2\n",
    "num_input_node = 4\n",
    "num_steps = 100\n",
    "train_data = RegSpikingDataset(train_input, train_label, sequence_length, num_steps)\n",
    "abc = [False,  True, False, False, False,  True, False, False]\n",
    "for i, row in enumerate(dataset[1]):\n",
    "    cnt = 0\n",
    "    for j, val in enumerate(row):\n",
    "        if val == abc[j]:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    if cnt == 8:\n",
    "        print(\"adsfdasf\", i)\n",
    "\n",
    "spike_input = SpikeInput(\n",
    "                         sequence_length,\n",
    "                         num_input_node,\n",
    "                         num_steps)\n",
    "\n",
    "\n",
    "dense = Dense(weights=125 * np.ones((8, 8)))\n",
    "spike_input.spikes_out.connect(dense.s_in)\n",
    "#layer1.spikes.get()\n",
    "\n",
    "\n",
    "for idx in range(2):\n",
    "    print(\"cur_idx\", idx)\n",
    "    dense.run(\n",
    "        condition=RunSteps(num_steps=num_steps),\n",
    "        run_cfg=Loihi1SimCfg(select_sub_proc_model=True,\n",
    "                             select_tag='fixed_pt'))\n",
    "    x = spike_input.input_data.get().astype(bool)\n",
    "    print(x.shape)\n",
    "    #spike_input.input_data.set(np.zeros((8,), dtype=bool))\n",
    "    #print()\n",
    "    #print(x)\n",
    "    #print(dataset[idx + 1][0, :])\n",
    "\n",
    "dense.stop()\n",
    "    #ground_truth = output_proc.gt_labels.get().astype(np.int32)\n",
    "    #predictions = output_proc.pred_labels.get().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed7d2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegModel(AbstractProcess):\n",
    "    \"\"\"A 3 layer feed-forward network with LIF and Dense Processes.\"\"\"\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Using pre-trained weights and biases\n",
    "        weights = []\n",
    "        f = open(path, 'rb')\n",
    "        w0 = np.load(f)\n",
    "        w1 = np.load(f)\n",
    "        w2 = np.load(f)\n",
    "        f.close()\n",
    "\n",
    "        self.spikes_in = InPort(shape=(w0.shape[1],))\n",
    "        #self.spikes_out = OutPort(shape=(w2.shape[0],))\n",
    "        self.w_dense0 = Var(shape=w0.shape, init=w0)\n",
    "        self.w_dense1 = Var(shape=w1.shape, init=w1)\n",
    "        self.w_dense2 = Var(shape=w2.shape, init=w2)\n",
    "        \n",
    "        # Up-level currents and voltages of LIF Processes\n",
    "        # for resetting (see at the end of the tutorial)\n",
    "        self.lif1_u = Var(shape=(w0.shape[0],), init=0)\n",
    "        self.lif1_v = Var(shape=(w0.shape[0],), init=0)\n",
    "        self.lif2_u = Var(shape=(w1.shape[0],), init=0)\n",
    "        self.lif2_v = Var(shape=(w1.shape[0],), init=0)\n",
    "        #self.oplif_u = Var(shape=(w2.shape[0],), init=0)\n",
    "        #self.oplif_v = Var(shape=(w2.shape[0],), init=0)\n",
    "        \n",
    "        \n",
    "class OutputProcess(AbstractProcess):\n",
    "    \"\"\"Process to gather spikes from 10 output LIF neurons and interpret the\n",
    "    highest spiking rate as the classifier output\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        shape = (10,)\n",
    "        n_img = kwargs.pop('num_images', 25)\n",
    "        self.num_images = Var(shape=(1,), init=n_img)\n",
    "        self.spikes_in = InPort(shape=shape)\n",
    "        self.label_in = InPort(shape=(1,))\n",
    "        self.spikes_accum = Var(shape=shape)  # Accumulated spikes for classification\n",
    "        self.num_steps_per_image = Var(shape=(1,), init=128)\n",
    "        self.pred_labels = Var(shape=(n_img,))\n",
    "        self.gt_labels = Var(shape=(n_img,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf2bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense            \n",
    "\n",
    "@implements(ImageClassifier)\n",
    "@requires(CPU)\n",
    "class PyImageClassifierModel(AbstractSubProcessModel):\n",
    "    def __init__(self, proc):\n",
    "        self.dense0 = Dense(weights=proc.w_dense0.init)\n",
    "        self.lif1 = LIF(shape=(64,), bias_mant=proc.b_lif1.init, vth=400,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense1 = Dense(weights=proc.w_dense1.init)\n",
    "        self.lif2 = LIF(shape=(64,), bias_mant=proc.b_lif2.init, vth=350,\n",
    "                        dv=0, du=4095)\n",
    "        self.dense2 = Dense(weights=proc.w_dense2.init)\n",
    "        self.output_lif = LIF(shape=(10,), bias_mant=proc.b_output_lif.init,\n",
    "                              vth=1, dv=0, du=4095)\n",
    "\n",
    "        proc.spikes_in.connect(self.dense0.s_in)\n",
    "        self.dense0.a_out.connect(self.lif1.a_in)\n",
    "        self.lif1.s_out.connect(self.dense1.s_in)\n",
    "        self.dense1.a_out.connect(self.lif2.a_in)\n",
    "        self.lif2.s_out.connect(self.dense2.s_in)\n",
    "        self.dense2.a_out.connect(self.output_lif.a_in)\n",
    "        self.output_lif.s_out.connect(proc.spikes_out)\n",
    "        \n",
    "        # Create aliases of SubProcess variables\n",
    "        proc.lif1_u.alias(self.lif1.u)\n",
    "        proc.lif1_v.alias(self.lif1.v)\n",
    "        proc.lif2_u.alias(self.lif2.u)\n",
    "        proc.lif2_v.alias(self.lif2.v)\n",
    "        proc.oplif_u.alias(self.output_lif.u)\n",
    "        proc.oplif_v.alias(self.output_lif.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23960ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=OutputProcess, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutputProcessModel(PyLoihiProcessModel):\n",
    "    label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "    spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "    num_images: int = LavaPyType(int, int, precision=32)\n",
    "    spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "    num_steps_per_image: int = LavaPyType(int, int, precision=32)\n",
    "    pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "    gt_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "        \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.current_img_id = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.time_step % self.num_steps_per_image == 0 and \\\n",
    "                self.time_step > 1:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        gt_label = self.label_in.recv()\n",
    "        pred_label = np.argmax(self.spikes_accum)\n",
    "        self.gt_labels[self.current_img_id] = gt_label\n",
    "        self.pred_labels[self.current_img_id] = pred_label\n",
    "        self.current_img_id += 1\n",
    "        self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        spk_in = self.spikes_in.recv()\n",
    "        self.spikes_accum = self.spikes_accum + spk_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaacfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
