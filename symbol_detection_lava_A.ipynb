{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138b6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import slayer from lava-dl\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "import IPython.display as display\n",
    "from matplotlib import animation\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.__version__\n",
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "print(\"init done\")\n",
    "\n",
    "\n",
    "def ber(a, b, fft_size=64):\n",
    "    def qpsk_demod(a):\n",
    "        a_real = np.real(a)\n",
    "        a_imag = np.imag(a)\n",
    "\n",
    "        a_real_bit = np.ones(a_real.shape)\n",
    "        a_real_bit[a_real < 0] = 0\n",
    "\n",
    "        a_imag_bit = np.ones(a_imag.shape)\n",
    "        a_imag_bit[a_imag < 0] = 0\n",
    "\n",
    "        a_bit = np.concatenate((a_imag_bit, a_real_bit), axis=0)\n",
    "        a_bit = a_bit.reshape((1, -1), order='F')\n",
    "        return a_bit\n",
    "    \n",
    "    carrier = np.hstack((np.arange(-26, -21), np.arange(-20, -7), np.arange(-6, 0),\n",
    "                         np.arange(1, 7), np.arange(8, 21), np.arange(22, 27))) + fft_size // 2\n",
    "    \n",
    "    assert a.shape == b.shape\n",
    "    a_list = a[:, carrier].reshape((1, -1))\n",
    "    b_list = b[:, carrier].reshape((1, -1))\n",
    "\n",
    "    a_bits = self.qpsk_demod(a_list)\n",
    "    b_bits = self.qpsk_demod(b_list)\n",
    "\n",
    "    error_count = np.sum(a_bits != b_bits)\n",
    "    total_bits = a_bits.shape[1]\n",
    "        \n",
    "    ber = float(error_count) / float(total_bits)\n",
    "    return ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [0]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23c\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a8c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ProcessLabel(label):\n",
    "#    min_val, max_val = np.min(label), np.max(label)\n",
    "#    label -= min_val\n",
    "#    return label\n",
    "#print(np.min(train_label))\n",
    "#train_label = ProcessLabel(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0acdc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7521\n",
      "(2,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 2\n",
    "nb_hidden  = 96\n",
    "nb_outputs = 2\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, SpikingDataset, ARegDataset\n",
    "train_data = ARegDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "print(len(train_data))\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1084390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_net = DNNNetwork(8, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce4a5c2-38de-466c-ab45-ae78ecfc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, testloader, model, DNN_model, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(DNN_model.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    #loss_fn = torch.nn.SmoothL1Loss()\n",
    "    loss_hist = []\n",
    "    DNN_model.train()\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        local_loss = []\n",
    "        for x_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            #output = model(x_local)\n",
    "            #output = output.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = DNN_model(x_local)\n",
    "            loss_val = 100 * loss_fn(output, y_local)\n",
    "            loss_val.backward()\n",
    "            #print(\"AAAA: \", DNN_model.fc2.weight)\n",
    "            #print(\"BBBB: \", DNN_model.fc1.weight.grad)\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "            \n",
    "        \n",
    "        #if e % 1 == 30 and e != 0:\n",
    "        #    print(\"Training accuracy: %.3f\"%(compute_ber(trainloader, net, \"train\")))\n",
    "        #    print(\"Test accuracy: %.3f\"%(compute_ber(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(mean_loss)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f574380-3878-4cbd-9a38-19da46e5efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2.373663954815622\n",
      "1\n",
      "2.1034454490547465\n",
      "2\n",
      "2.1808609483858286\n",
      "3\n",
      "2.1080262950795183\n",
      "4\n",
      "1.9465129713890916\n",
      "5\n",
      "1.779584568688425\n",
      "6\n",
      "1.8247970558892368\n",
      "7\n",
      "1.685951786778741\n",
      "8\n",
      "1.626614322573128\n",
      "9\n",
      "1.5619444118465406\n",
      "10\n",
      "1.5440970330925312\n",
      "11\n",
      "1.6083501372959907\n",
      "12\n",
      "1.6381293043999348\n",
      "13\n",
      "1.6143571149747251\n",
      "14\n",
      "1.5978078427961317\n",
      "15\n",
      "1.5677477534292108\n",
      "16\n",
      "1.5910550993630441\n",
      "17\n",
      "1.6298217919923492\n",
      "18\n",
      "1.5354205636402307\n",
      "19\n",
      "1.526179462544999\n",
      "20\n",
      "1.5661565636174153\n",
      "21\n",
      "1.5646725034309645\n",
      "22\n",
      "1.5063735386830266\n",
      "23\n",
      "1.4417925172690618\n",
      "24\n",
      "1.414823699174291\n",
      "25\n",
      "1.444418061082646\n",
      "26\n",
      "1.431042138171398\n",
      "27\n",
      "1.3755614677980794\n",
      "28\n",
      "1.553071953229985\n",
      "29\n",
      "1.878374686180535\n",
      "30\n",
      "1.6083596034322756\n",
      "31\n",
      "1.4910278062067799\n",
      "32\n",
      "1.4243283439743317\n",
      "33\n",
      "1.3698133050890293\n",
      "34\n",
      "1.3122761604391922\n",
      "35\n",
      "1.4115007235589674\n",
      "36\n",
      "1.3392519502569054\n",
      "37\n",
      "1.4835870436913634\n",
      "38\n",
      "1.4470641441264396\n",
      "39\n",
      "1.3192526546575256\n",
      "40\n",
      "1.3300257726114686\n",
      "41\n",
      "1.316703704580412\n",
      "42\n",
      "1.37579431031215\n",
      "43\n",
      "1.3452067187024375\n",
      "44\n",
      "1.438544025423668\n",
      "45\n",
      "1.306538727829012\n",
      "46\n",
      "1.2942753549096948\n",
      "47\n",
      "1.397918895202673\n",
      "48\n",
      "1.3299728534736877\n",
      "49\n",
      "1.471935632117724\n",
      "50\n",
      "1.3704105322643862\n",
      "51\n",
      "1.3260854245242426\n",
      "52\n",
      "1.3151966409157898\n",
      "53\n",
      "1.3275647542234195\n",
      "54\n",
      "1.293780916449377\n",
      "55\n",
      "1.2781507640571919\n",
      "56\n",
      "1.3635010876519196\n",
      "57\n",
      "1.4163675627718537\n",
      "58\n",
      "1.2860936604566493\n",
      "59\n",
      "1.2105848450781935\n",
      "60\n",
      "1.2850976993282468\n",
      "61\n",
      "1.2926340255949458\n",
      "62\n",
      "1.2260649658865848\n",
      "63\n",
      "1.4157389468055661\n",
      "64\n",
      "1.366697296626487\n",
      "65\n",
      "1.261635063689644\n",
      "66\n",
      "1.1948542646724352\n",
      "67\n",
      "1.239548894055819\n",
      "68\n",
      "1.2320005646827867\n",
      "69\n",
      "1.1915513274528213\n",
      "70\n",
      "1.3320440704287109\n",
      "71\n",
      "1.2806512428037191\n",
      "72\n",
      "1.3841396069027863\n",
      "73\n",
      "1.46765550456436\n",
      "74\n",
      "1.3638121221467094\n",
      "75\n",
      "1.402867983458406\n",
      "76\n",
      "1.4317771697701034\n",
      "77\n",
      "1.2064809650182724\n",
      "78\n",
      "1.177967584486735\n",
      "79\n",
      "1.2972298433720055\n",
      "80\n",
      "1.3140510955225613\n",
      "81\n",
      "1.2018279825984421\n",
      "82\n",
      "1.222277745351953\n",
      "83\n",
      "1.2239061946333465\n",
      "84\n",
      "1.3398589663586373\n",
      "85\n",
      "1.271234281361103\n",
      "86\n",
      "1.178046124213833\n",
      "87\n",
      "1.187745320468636\n",
      "88\n",
      "1.2683549573234583\n",
      "89\n",
      "1.241407297677913\n",
      "90\n",
      "1.2921483572256767\n",
      "91\n",
      "1.144435688206567\n",
      "92\n",
      "1.1659415801197797\n",
      "93\n",
      "1.2314200591142053\n",
      "94\n",
      "1.2681289010886418\n",
      "95\n",
      "1.1232662734780776\n",
      "96\n",
      "1.1589494871638588\n",
      "97\n",
      "1.1397733510298245\n",
      "98\n",
      "1.1597971715411897\n",
      "99\n",
      "1.2286239049823608\n",
      "100\n",
      "1.0842099819900626\n",
      "101\n",
      "0.9966880338171781\n",
      "102\n",
      "0.9533203208534899\n",
      "103\n",
      "0.94079360290099\n",
      "104\n",
      "0.9262155448481187\n",
      "105\n",
      "0.9065224711420172\n",
      "106\n",
      "0.8974903110983008\n",
      "107\n",
      "0.8903954450861883\n",
      "108\n",
      "0.8902747200454696\n",
      "109\n",
      "0.8840680387565645\n",
      "110\n",
      "0.8738301176009542\n",
      "111\n",
      "0.8642361161172769\n",
      "112\n",
      "0.8580508110886913\n",
      "113\n",
      "0.8591244621675903\n",
      "114\n",
      "0.8472343767535383\n",
      "115\n",
      "0.8526486039666806\n",
      "116\n",
      "0.8457294617921619\n",
      "117\n",
      "0.8424935129992033\n",
      "118\n",
      "0.8522258679998123\n",
      "119\n",
      "0.8377131895493652\n",
      "120\n",
      "0.8359391864831165\n",
      "121\n",
      "0.8382944712194346\n",
      "122\n",
      "0.8301163492566448\n",
      "123\n",
      "0.8269210464747275\n",
      "124\n",
      "0.8242115415948428\n",
      "125\n",
      "0.8252651293651533\n",
      "126\n",
      "0.81774389383904\n",
      "127\n",
      "0.8173727500804905\n",
      "128\n",
      "0.8178211890034757\n",
      "129\n",
      "0.8125275538887008\n",
      "130\n",
      "0.8138205571952513\n",
      "131\n",
      "0.8263053421751928\n",
      "132\n",
      "0.807723212671482\n",
      "133\n",
      "0.7988374687541845\n",
      "134\n",
      "0.8107782751321793\n",
      "135\n",
      "0.790317881315694\n",
      "136\n",
      "0.7920238259485213\n",
      "137\n",
      "0.7881216722130144\n",
      "138\n",
      "0.7851701960662159\n",
      "139\n",
      "0.7869781148541024\n",
      "140\n",
      "0.7847991269713236\n",
      "141\n",
      "0.787711668949006\n",
      "142\n",
      "0.782927805068508\n",
      "143\n",
      "0.7847529979327977\n",
      "144\n",
      "0.7834158846003524\n",
      "145\n",
      "0.788201886971118\n",
      "146\n",
      "0.7783018556439271\n",
      "147\n",
      "0.7864936215140051\n",
      "148\n",
      "0.7823307130296352\n",
      "149\n",
      "0.7768569399239653\n",
      "150\n",
      "0.7771538194837206\n",
      "151\n",
      "0.7732606993640884\n",
      "152\n",
      "0.7757734748519073\n",
      "153\n",
      "0.7757855196625499\n",
      "154\n",
      "0.7804457448044065\n",
      "155\n",
      "0.7704635233760385\n",
      "156\n",
      "0.7693365956262007\n",
      "157\n",
      "0.8589913245227377\n",
      "158\n",
      "0.7789208956015439\n",
      "159\n",
      "0.7733157410965128\n",
      "160\n",
      "0.7641777597936028\n",
      "161\n",
      "0.7651969110435348\n",
      "162\n",
      "0.7678030954074051\n",
      "163\n",
      "0.7635397685028739\n",
      "164\n",
      "0.7656995369342424\n",
      "165\n",
      "0.7621880831607317\n",
      "166\n",
      "0.7622119469599704\n",
      "167\n",
      "0.7629585616858834\n",
      "168\n",
      "0.7636745778559628\n",
      "169\n",
      "0.8134056109998186\n",
      "170\n",
      "0.7712728065454354\n",
      "171\n",
      "0.764176154540757\n",
      "172\n",
      "0.7572345549903684\n",
      "173\n",
      "0.7626942077935752\n",
      "174\n",
      "0.7610107110971112\n",
      "175\n",
      "0.7572706166212841\n",
      "176\n",
      "0.7538533779019017\n",
      "177\n",
      "0.7537049131499509\n",
      "178\n",
      "0.7533468432799455\n",
      "179\n",
      "0.7523781203870046\n",
      "180\n",
      "0.7547945302548045\n",
      "181\n",
      "0.7766495912762011\n",
      "182\n",
      "0.7575740501032038\n",
      "183\n",
      "0.7559531213620961\n",
      "184\n",
      "0.7614418806160911\n",
      "185\n",
      "0.7493269371768554\n",
      "186\n",
      "0.7496921090503871\n",
      "187\n",
      "0.7499243279887458\n",
      "188\n",
      "0.7593494163731397\n",
      "189\n",
      "0.7615141038924961\n",
      "190\n",
      "0.7527087528132281\n",
      "191\n",
      "0.7485072470064891\n",
      "192\n",
      "0.7461878820243528\n",
      "193\n",
      "0.7422351256896884\n",
      "194\n",
      "0.7455879406277406\n",
      "195\n",
      "0.7517664532287646\n",
      "196\n",
      "0.7678204993322745\n",
      "197\n",
      "0.7501774274317895\n",
      "198\n",
      "0.7528270950256768\n",
      "199\n",
      "0.7468009993939076\n",
      "200\n",
      "0.7294976146560226\n",
      "201\n",
      "0.7348673756597406\n",
      "202\n",
      "0.724752766727391\n",
      "203\n",
      "0.7260331968634816\n",
      "204\n",
      "0.7235049253045502\n",
      "205\n",
      "0.7223777604936543\n",
      "206\n",
      "0.7370514836856874\n",
      "207\n",
      "0.7219809974401684\n",
      "208\n",
      "0.7217496353185783\n",
      "209\n",
      "0.7226671643428884\n",
      "210\n",
      "0.7204787556587134\n",
      "211\n",
      "0.720498151082735\n",
      "212\n",
      "0.7200925178762715\n",
      "213\n",
      "0.7203990501683142\n",
      "214\n",
      "0.7204046789872445\n",
      "215\n",
      "0.7203292303039865\n",
      "216\n",
      "0.7203392194489301\n",
      "217\n",
      "0.7209032280212742\n",
      "218\n",
      "0.7201756831195395\n",
      "219\n",
      "0.7190789334649631\n",
      "220\n",
      "0.7192931823685007\n",
      "221\n",
      "0.7186729027652892\n",
      "222\n",
      "0.7209534723374803\n",
      "223\n",
      "0.7187924138507096\n",
      "224\n",
      "0.7192876659081144\n",
      "225\n",
      "0.7218177496629247\n",
      "226\n",
      "0.7190294643327341\n",
      "227\n",
      "0.7186984563783064\n",
      "228\n",
      "0.7206364865020171\n",
      "229\n",
      "0.719067021699275\n",
      "230\n",
      "0.7200012989973618\n",
      "231\n",
      "0.7190649111644697\n",
      "232\n",
      "0.7197562709955846\n",
      "233\n",
      "0.7491910256824251\n",
      "234\n",
      "0.7370465291758715\n",
      "235\n",
      "0.7195352514163923\n",
      "236\n",
      "0.7183659937927278\n",
      "237\n",
      "0.7188715362700365\n",
      "238\n",
      "0.7169390419277094\n",
      "239\n",
      "0.7169386895405034\n",
      "240\n",
      "0.722789998150478\n",
      "241\n",
      "0.7177085800696228\n",
      "242\n",
      "0.7176288278552435\n",
      "243\n",
      "0.7184474961990017\n",
      "244\n",
      "0.7168407578778974\n",
      "245\n",
      "0.7174516073980574\n",
      "246\n",
      "0.7167610389701391\n",
      "247\n",
      "0.7170027561359487\n",
      "248\n",
      "0.7201126605524855\n",
      "249\n",
      "0.716537278192907\n",
      "250\n",
      "0.7161581671512607\n",
      "251\n",
      "0.7204041364839522\n",
      "252\n",
      "0.7161581837493232\n",
      "253\n",
      "0.7189241602259168\n",
      "254\n",
      "0.7175335222381657\n",
      "255\n",
      "0.7170363847734564\n",
      "256\n",
      "0.7182122210072259\n",
      "257\n",
      "0.7163080730933254\n",
      "258\n",
      "0.7157366830871393\n",
      "259\n",
      "0.716046896526369\n",
      "260\n",
      "0.7168477119530662\n",
      "261\n",
      "0.7156016041793055\n",
      "262\n",
      "0.7170778565992744\n",
      "263\n",
      "0.716931505097171\n",
      "264\n",
      "0.7156886211517504\n",
      "265\n",
      "0.7159228144308268\n",
      "266\n",
      "0.7172450678328336\n",
      "267\n",
      "0.7153134411358733\n",
      "268\n",
      "0.7150959935575977\n",
      "269\n",
      "0.7154181799141027\n",
      "270\n",
      "0.7154063718488156\n",
      "271\n",
      "0.7148658815471424\n",
      "272\n",
      "0.7414929226545964\n",
      "273\n",
      "0.7158397511910584\n",
      "274\n",
      "0.7168910240722914\n",
      "275\n",
      "0.7145979888737202\n",
      "276\n",
      "0.7162905036140297\n",
      "277\n",
      "0.7223933962947231\n",
      "278\n",
      "0.7150263822621713\n",
      "279\n",
      "0.7146132895880837\n",
      "280\n",
      "0.7161070133669901\n",
      "281\n",
      "0.7253716120780525\n",
      "282\n",
      "0.7181755185632382\n",
      "283\n",
      "0.7177767331822443\n",
      "284\n",
      "0.7140898116217074\n",
      "285\n",
      "0.7162745834912284\n",
      "286\n",
      "0.7145738334600198\n",
      "287\n",
      "0.7172493903061091\n",
      "288\n",
      "0.7139808020664978\n",
      "289\n",
      "0.713961521068872\n",
      "290\n",
      "0.7135683713772855\n",
      "291\n",
      "0.7151290510418051\n",
      "292\n",
      "0.7145709584830171\n",
      "293\n",
      "0.7154254207419137\n",
      "294\n",
      "0.7142640727935201\n",
      "295\n",
      "0.7263309273679378\n",
      "296\n",
      "0.7133845637149919\n",
      "297\n",
      "0.7135331967245724\n",
      "298\n",
      "0.7178890914735148\n",
      "299\n",
      "0.7146639294796071\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, train_loader, dnn_net, dnn_net, lr=1e-2, nb_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d89d458-a244-4a80-8684-c1b08eb3d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1089, 0.1195]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dnn_net.eval()\n",
    "error = 0.0\n",
    "size = 20\n",
    "for i in range(size):\n",
    "    input, target = train_data[i]\n",
    "    target = torch.tensor(target).float()\n",
    "    input = torch.tensor(input).float()\n",
    "\n",
    "    output = dnn_net(input.unsqueeze(dim=0).to(device))\n",
    "\n",
    "    error += torch.sqrt((output - target) ** 2)\n",
    "print(error / size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808d7c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
