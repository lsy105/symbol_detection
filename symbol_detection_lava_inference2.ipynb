{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138b6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.proc import io\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import RefPort\n",
    "\n",
    "from lava.lib.dl import netx\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Type   |  W  |  H  |  C  | ker | str | pad | dil | grp |delay|\n",
      "|Dense     |    1|    1|   64|     |     |     |     |     |False|\n",
      "|Dense     |    1|    1|  128|     |     |     |     |     |False|\n",
      "|Dense     |    1|    1|    2|     |     |     |     |     |False|\n"
     ]
    }
   ],
   "source": [
    "net = netx.hdf5.Network(net_config='net_snn.net')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475f0f65-0d33-4aed-bdb9-2cda04c09686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 layers in network:\n",
      "Dense : Process_1 , shape : (64,)\n",
      "Dense : Process_4 , shape : (128,)\n",
      "Dense : Process_7 , shape : (2,)\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(net)} layers in network:')\n",
    "\n",
    "for l in net.layers:\n",
    "    print(f'{l.block:5s} : {l.name:10s}, shape : {l.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1601b4-d62f-4448-8f93-72b0167123c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [0]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23c\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49db7cbc-26e4-4494-9906-ecfdeb650216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7521\n",
      "(2,)\n",
      "(8, 100)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 2\n",
    "nb_hidden  = 96\n",
    "nb_outputs = 2\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, SpikingDataset, ARegDataset, RegSpikingDataset, RegTorchSpikingDataset\n",
    "train_data = RegTorchSpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "if np.isscalar(train_data[0][1]):\n",
    "    print(\"True\")\n",
    "print(len(train_data))\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b0bc7b2-a3cb-46c9-917f-b8644f8c7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Process level primitives\n",
    "import typing as ty \n",
    "from typing import Iterable, Tuple, Union\n",
    "\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "# Import parent classes for ProcessModels\n",
    "from lava.magma.core.model.sub.model import AbstractSubProcessModel\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "\n",
    "# Import ProcessModel ports, data-types\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "\n",
    "# Import execution protocol and hardware resources\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.resources import CPU\n",
    "\n",
    "# Import decorators\n",
    "from lava.magma.core.decorator import implements, requires, tag\n",
    "\n",
    "\n",
    "class SpikeInput(AbstractProcess):\n",
    "    \"\"\"Reads image data from the MNIST dataset and converts it to spikes.\n",
    "    The resulting spike rate is proportional to the pixel value.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset: Iterable,\n",
    "                 sequence_length : ty.Optional[int] = 2,\n",
    "                 num_input_node : ty.Optional[int] = 4,\n",
    "                 num_steps: ty.Optional[int] = 100):\n",
    "        super().__init__()\n",
    "        self.sequence_length = Var(shape=(1,), init=sequence_length)\n",
    "        self.num_input_node = Var(shape=(1,), init=num_input_node) \n",
    "        shape = (sequence_length * num_input_node,)\n",
    "        self.spikes_out = OutPort(shape=shape)\n",
    "        self.num_steps = Var(shape=(1,), init=num_steps)\n",
    "        self.input_data = Var(shape=shape)\n",
    "        self.proc_params['saved_dataset'] = dataset\n",
    "        \n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PySpikeInputModel(PyLoihiProcessModel):\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    input_data: np.ndarray = LavaPyType(np.ndarray, bool, precision=1)\n",
    "    num_steps: int = LavaPyType(int, int, precision=32)\n",
    "    sequence_length: int = LavaPyType(int, int, precision=32)\n",
    "    num_input_node: int = LavaPyType(int, int, precision=32)\n",
    "    \n",
    "    def __init__(self, proc_params):\n",
    "        super().__init__(proc_params=proc_params)\n",
    "        self.dataset = self.proc_params['saved_dataset']\n",
    "        self.curr_id = 0\n",
    "        self.sample_time = 0\n",
    "\n",
    "    def post_guard(self):\n",
    "        \"\"\"Guard function for PostManagement phase.\n",
    "        \"\"\"\n",
    "        if self.sample_time == self.num_steps:\n",
    "            return True\n",
    "        return False\n",
    "        #return True\n",
    "\n",
    "    def run_post_mgmt(self):\n",
    "        \"\"\"Post-Management phase: executed only when guard function above \n",
    "        returns True.\n",
    "        \"\"\"\n",
    "        self.curr_id += 1\n",
    "        self.sample_time = 0\n",
    "    \n",
    "    def run_spk(self):\n",
    "        \"\"\"Spiking phase: executed unconditionally at every time-step\n",
    "        \"\"\"\n",
    "        output = self.dataset[self.curr_id][0][:, self.sample_time]\n",
    "        print(self.sample_time, self.curr_id, output)\n",
    "        self.spikes_out.send(output)\n",
    "        self.sample_time += 1\n",
    "        #print(self.time_step)\n",
    "        #print(self.input_data)\n",
    "        #print(self.dataset[self.curr_id][(self.time_step - 1) % (self.num_steps)])\n",
    "        \n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@tag('fixed_pt')\n",
    "class PySpikeModelFixed(PySpikeInputModel):\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32)\n",
    "    input_data: np.ndarray = LavaPyType(np.ndarray, np.int32)\n",
    "\n",
    "\n",
    "@implements(proc=SpikeInput, protocol=LoihiProtocol)\n",
    "@tag('floating_pt')\n",
    "class PySpikeModelFloat(PySpikeInputModel):\n",
    "    spikes_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, float)\n",
    "    input_data: np.ndarray = LavaPyType(np.ndarray, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9de6dfbc-aaf1-4944-ad17-7b68f89e6c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7521\n",
      "(2,)\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset, SpikingDataset, ARegDataset, RegSpikingDataset, RegTorchSpikingDataset\n",
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.dense.process import Dense  \n",
    "\n",
    "train_data = RegTorchSpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "print(len(train_data))\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][0].shape)\n",
    "sequence_length = 2\n",
    "num_input_node = 4\n",
    "\n",
    "spike_input = SpikeInput(\n",
    "                         dataset = train_data,\n",
    "                         sequence_length = sequence_length,\n",
    "                         num_input_node = num_input_node,\n",
    "                         num_steps = nb_steps)\n",
    "\n",
    "\n",
    "dense = Dense(weights=125 * np.ones((8, 8)))\n",
    "spike_input.spikes_out.connect(dense.s_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93bb47bd-94d8-4b55-8890-afe9c7e1b10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 0 1]\n",
      "0\n",
      "[0 0 0 0 1 1 0 1]\n",
      "1\n",
      "[0 0 0 0 1 0 0 1]\n",
      "2\n",
      "[1 1 0 1 0 1 0 1]\n",
      "0\n",
      "[0 1 0 1 0 1 0 0]\n",
      "1\n",
      "[1 1 0 1 0 1 0 0]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2):\n",
    "    data = train_data[idx][0]\n",
    "    for j in range(data.shape[1]):\n",
    "        print(data[:, j])\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbad40fa-218e-48ac-b526-cadf63633c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_idx 0\n",
      "0 0 [0 0 0 0 1 1 0 1]\n",
      "1 0 [0 0 0 0 1 1 0 1]\n",
      "2 0 [0 0 0 0 1 1 0 1]\n",
      "0 1 [1 0 0 1 0 1 0 0]\n",
      "1 1 [0 1 0 1 0 1 0 1]\n",
      "2 1 [1 1 0 1 0 1 0 1]\n",
      "cur_idx 1\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2):\n",
    "    print(\"cur_idx\", idx)\n",
    "    dense.run(\n",
    "        condition=RunSteps(num_steps=nb_steps),\n",
    "        run_cfg=Loihi1SimCfg(select_sub_proc_model=True,\n",
    "                             select_tag='fixed_pt'))\n",
    "    x = spike_input.input_data.get().astype(bool)\n",
    "    \n",
    "dense.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0a7925-bd90-4458-b3d3-f1daf5097c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc import io\n",
    "\n",
    "# Instantiate the processes\n",
    "dataloader = io.dataloader.SpikeDataloader(dataset=train_data, offset=100)\n",
    "output_logger = io.sink.RingBuffer(shape=net.out_layer.shape, buffer=nb_steps)\n",
    "#gt_logger = io.sink.RingBuffer(shape=(2,), buffer=nb_steps)\n",
    "\n",
    "\n",
    "# Connect the input to the network:\n",
    "#dataloader.ground_truth.connect(gt_logger.a_in)\n",
    "dataloader.s_out.connect(net.inp)\n",
    "\n",
    "# Connect network-output to the output process\n",
    "net.out.connect(output_logger.a_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d53f54-70bf-41d2-8a1d-1f5297ff3ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = torch.load('./net_dnn.pth', map_location=torch.device('cpu'))\n",
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        #self.fc2 = nn.Linear(64, 128)\n",
    "        #self.fc3 = nn.Linear(128, 128)\n",
    "        #self.fc4 = nn.Linear(128, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc3(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "net_dnn = DNNNetwork(2 * 100, 2).to(device)\n",
    "net_dnn.load_state_dict(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18e62c4d-1797-44cf-bac2-338c440e1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRunConfig(Loihi1SimCfg):\n",
    "    def select(self, proc, proc_models):\n",
    "        # customize run config to always use float model for io.sink.RingBuffer\n",
    "        if isinstance(proc, io.sink.RingBuffer):\n",
    "            return io.sink.PyReceiveModelFloat\n",
    "        else:\n",
    "            return super().select(proc, proc_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60bfee5-8708-4a45-99d8-57d4631ea1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 2, 100])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OutPort' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     results \u001b[38;5;241m=\u001b[39m net_dnn(results)\n\u001b[1;32m     11\u001b[0m     dataloader\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#gts = gt_logger.data.get()\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OutPort' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    run_condition = RunSteps(num_steps=nb_steps)\n",
    "    run_config = Loihi1SimCfg(select_tag='fixed_pt', select_sub_proc_model=True)\n",
    "    net.run(condition=run_condition, run_cfg=run_config) \n",
    "    results = output_logger.data.get()\n",
    "    results = torch.Tensor(results).to(device)\n",
    "    results = torch.unsqueeze(results, dim=0)\n",
    "    print(type(results), results.shape)\n",
    "    results = net_dnn(results)\n",
    "    \n",
    "    dataloader.data.get().astype(bool)\n",
    "    #dataloader.s_out.get().astype(bool)\n",
    "    print(results)\n",
    "#gts = gt_logger.data.get()\n",
    "net.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffec7eeb-0030-4a50-8b98-0d48739dc803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0148, -0.1659]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf7fc0-dfea-4b18-b5a4-c75fb998e035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lava:Python",
   "language": "python",
   "name": "conda-env-lava-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
