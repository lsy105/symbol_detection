{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "138b6027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "\n",
    "from Loss import ber_loss\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import slayer from lava-dl\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "import IPython.display as display\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.__version__\n",
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4) (7521, 4)\n",
      "test_input_diff:  tensor(4.2885e-10, dtype=torch.float64)\n",
      "train_input_diff:  tensor(4.4511e-11, dtype=torch.float64)\n",
      "train_label_diff:  tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [55]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "RC_test_input = np.load('gt_test_input_1.npy')\n",
    "RC_train_input = np.load('gt_train_input_1.npy')\n",
    "RC_train_label = np.load('gt_train_label_1.npy')\n",
    "\n",
    "print(RC_test_input.shape, test_input.shape)\n",
    "print(\"test_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_test_input), torch.tensor(test_input)))\n",
    "\n",
    "print(\"train_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_input), torch.tensor(train_input)))\n",
    "\n",
    "print(\"train_label_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_label), torch.tensor(train_label)))\n",
    "\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std\n",
    "train_label = 1.0 * train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61a8c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4)\n",
      "(7521, 4)\n",
      "(7521, 2)\n",
      "(89, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7395dfe-dc16-458e-989e-b39bfcc397e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4  L1_idx        L1        L2\n",
      "0  0.004552  0.004552 -1.883590  0.270283       0 -0.004627  0.003909\n",
      "1 -1.883590  0.270283  0.808491 -5.124171       1 -0.010139  0.006723\n",
      "2  0.808491 -5.124171  2.429831  1.345677       2 -0.007300 -0.000566\n",
      "3  2.429831  1.345677  0.284437  5.142469       3  0.007015 -0.005416\n",
      "4  0.284437  5.142469  0.000128  3.776303       4  0.007815 -0.000455\n",
      "          1         2         3         4  L1_idx        L1        L2\n",
      "0 -0.662297  0.678553 -0.213717 -1.232259       1 -0.010139  0.006723\n",
      "1 -0.213717 -1.232259 -0.925615 -0.693978       2 -0.007300 -0.000566\n",
      "2 -0.925615 -0.693978 -1.297989  0.321551       3  0.007015 -0.005416\n",
      "3 -1.297989  0.321551  0.258551 -0.845407       4  0.007815 -0.000455\n",
      "4  0.258551 -0.845407  0.521464  0.135325       5  0.005713  0.000847\n",
      "(6001, 7)\n",
      "(1520, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def pre_processing(train_input, train_label):\n",
    "    idx_p = 10\n",
    "    begin = 0 # N_total_frame * N_sync_frame\n",
    "    \n",
    "    # label index for data\n",
    "    train_input_df = pd.DataFrame(train_input, columns = ['1','2', '3', '4'])\n",
    "    train_input_df['L1_idx'] = train_input_df.index % idx_p\n",
    "\n",
    "    # label index for label\n",
    "    train_label_df = pd.DataFrame(train_label, columns = ['L1','L2'])\n",
    "    train_label_df['L1_idx'] = train_label_df.index % idx_p\n",
    "    \n",
    "    # split training and testing data\n",
    "    test_input_df, test_label_df = train_input_df.iloc[75* 80 + 1:, :], train_label_df.iloc[75* 80 + 1:, :]\n",
    "    train_input_df, train_label_df = train_input_df.iloc[:75* 80 + 1, :], train_label_df.iloc[:75* 80 + 1, :]\n",
    "\n",
    "    # group by \n",
    "    mapping = train_label_df.loc[begin:, :].groupby(by='L1_idx').mean().reset_index().loc[:, ['L1', 'L2', 'L1_idx']] \n",
    "    \n",
    "    train_input_df = pd.merge(train_input_df, mapping, how='left', on='L1_idx')\n",
    "\n",
    "    #train_input_df = pd.get_dummies(train_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    train_input_df = train_input_df.loc[begin:, :]\n",
    "\n",
    "\n",
    "    print(train_input_df.head())\n",
    "    \n",
    "    # testing data\n",
    "    # group by\n",
    "    test_input_df = test_input_df.merge(mapping, how = 'left', on='L1_idx')\n",
    "\n",
    "    #test_input_df = pd.get_dummies(test_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    print(test_input_df.head())\n",
    "\n",
    "    train_input = train_input_df.to_numpy()\n",
    "    test_input = test_input_df.to_numpy()\n",
    "    \n",
    "    train_label = train_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    test_label = test_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    \n",
    "    print(train_input.shape)\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    \n",
    "    return train_input, train_label, test_input, test_label\n",
    "\n",
    "train_input, train_label, test_input, test_label = pre_processing(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n",
      "(32, 100)\n",
      "(1,)\n",
      "(0,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 8\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, RegTorchSeasonalitySpikingDataset, RegSpikingDataset, RegTorchSpikingDataset\n",
    "train_data = RegTorchSeasonalitySpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "test_data = RegTorchSeasonalitySpikingDataset(test_input, test_label, nb_inputs, nb_steps)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "       # neuron_params = {\n",
    "       #         'threshold'     : 0.1,\n",
    "       #         'current_decay' : 1,\n",
    "       #         'voltage_decay' : 0.1,\n",
    "       #         'requires_grad' : True,     \n",
    "       #     }\n",
    "        #neuron_params_drop = {**neuron_params, 'dropout' : slayer.neuron.Dropout(p=0.05),}\n",
    "        neuron_params = {\n",
    "                'threshold'     : 1.25,\n",
    "                'current_decay' : 0.25,\n",
    "                'voltage_decay' : 0.03,\n",
    "                'tau_grad'      : 0.03,\n",
    "                'scale_grad'    : 100,\n",
    "                'requires_grad' : True,     \n",
    "            }\n",
    "        \n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "                #slayer.block.cuba.Input(neuron_params),\n",
    "                slayer.block.cuba.Recurrent(neuron_params, input_size, 64, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 32, 64, weight_norm=True, delay=True),\n",
    "                slayer.block.cuba.Dense(neuron_params, 64, 128, weight_norm=True, delay=True),\n",
    "                slayer.block.cuba.Dense(neuron_params, 128, output_size, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, input_size, 64, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 64, 128, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 128, output_size, weight_scale=2, weight_norm=True)\n",
    "                #slayer.block.cuba.Recurrent(cuba_params, 100, 50),\n",
    "                #slayer.block.cuba.KWTA(cuba_params, 50, 50, num_winners=5)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, spike):\n",
    "        for block in self.blocks:\n",
    "            spike = block(spike)\n",
    "        return spike\n",
    "\n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "\n",
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16 + 1 + 24, 8)\n",
    "        self.fc3 = nn.Linear(8, 2)\n",
    "        #self.fc3 = nn.Linear(128, 128)\n",
    "        #self.fc4 = nn.Linear(128, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x, x1, x2):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        #x = torch.cat((x, x1), axis=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x) \n",
    "        x = torch.cat((x, x1, x2), axis=1)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc3(x)\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc3(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1084390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.neuron.current_decay torch.Size([1])\n",
      "blocks.0.neuron.voltage_decay torch.Size([1])\n",
      "blocks.0.delay.delay torch.Size([1])\n",
      "blocks.0.input_synapse.weight_g torch.Size([64, 1, 1, 1, 1])\n",
      "blocks.0.input_synapse.weight_v torch.Size([64, 32, 1, 1, 1])\n",
      "blocks.0.recurrent_synapse.weight_g torch.Size([64, 1, 1, 1, 1])\n",
      "blocks.0.recurrent_synapse.weight_v torch.Size([64, 64, 1, 1, 1])\n",
      "blocks.1.neuron.current_decay torch.Size([1])\n",
      "blocks.1.neuron.voltage_decay torch.Size([1])\n",
      "blocks.1.delay.delay torch.Size([1])\n",
      "blocks.1.synapse.weight_g torch.Size([128, 1, 1, 1, 1])\n",
      "blocks.1.synapse.weight_v torch.Size([128, 64, 1, 1, 1])\n",
      "blocks.2.neuron.current_decay torch.Size([1])\n",
      "blocks.2.neuron.voltage_decay torch.Size([1])\n",
      "blocks.2.synapse.weight_g torch.Size([2, 1, 1, 1, 1])\n",
      "blocks.2.synapse.weight_v torch.Size([2, 128, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "net_snn = Network(nb_inputs * 4, 2).to(device)\n",
    "net_dnn = DNNNetwork(2 * 100, 2).to(device)\n",
    "\n",
    "for name, weight in net_snn.named_parameters():\n",
    "    print(name, weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8441bd-8c48-4451-a52d-88763313aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99/3893188529.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_99/3893188529.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_99/3893188529.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_99/3893188529.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x17 and 41x8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     target_time \u001b[38;5;241m=\u001b[39m rc\u001b[38;5;241m.\u001b[39mtime_to_freq(labels, num_frame, remove_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtesting ber: \u001b[39m\u001b[38;5;124m\"\u001b[39m, rc\u001b[38;5;241m.\u001b[39mmy_new_test(predict_time, target_time))\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_loader, net_snn, net_dnn, rc, num_frame)\u001b[0m\n\u001b[1;32m     12\u001b[0m     input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input2)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m     output \u001b[38;5;241m=\u001b[39m net_snn(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnet_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m     all_output\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     19\u001b[0m all_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(all_output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mDNNNetwork.forward\u001b[0;34m(self, x, x1, x2)\u001b[0m\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x) \n\u001b[1;32m     63\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, x1, x2), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x17 and 41x8)"
     ]
    }
   ],
   "source": [
    "def test(test_loader, net_snn, net_dnn, rc, num_frame = 19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    print(\"testing MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    print(\"testing MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    print(\"testing MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    print(\"percent loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing ber: \", rc.my_new_test(predict_time, target_time))\n",
    "\n",
    "test(test_loader, net_snn, net_dnn, rc, num_frame=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bce4a5c2-38de-466c-ab45-ae78ecfc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(output, target):\n",
    "    #loss = (output - target) ** 2 / (target ** 2 + 1e-6)\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def train(trainloader, testloader, model, DNN_model, rc, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    params = list(model.parameters()) + list(DNN_model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    #loss_fn = torch.nn.L1Loss()\n",
    "    loss_fn = ber_loss\n",
    "    loss_hist = []\n",
    "    DNN_model.train()\n",
    "    \n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        local_loss = []\n",
    "        for x_local, x1_local, x2_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            #output = model(x_local)\n",
    "            #output = output.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_local)\n",
    "            output = DNN_model(output, x1_local, x2_local)\n",
    "            loss_val = loss_fn(output, y_local) \n",
    "            loss_val.backward()\n",
    "            #print(\"AAAA: \", DNN_model.fc2.weight)\n",
    "            #print(\"BBBB: \", DNN_model.fc1.weight.grad)\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "            \n",
    "        \n",
    "        #if e % 1 == 30 and e != 0:\n",
    "        #    print(\"Training accuracy: %.3f\"%(compute_ber(trainloader, net, \"train\")))\n",
    "        #    print(\"Test accuracy: %.3f\"%(compute_ber(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(mean_loss)\n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        #test(testloader, model, DNN_model)\n",
    "        #test_train(trainloader, model, DNN_model)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f574380-3878-4cbd-9a38-19da46e5efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.12008890255968621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/3893188529.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_96/3893188529.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_96/3893188529.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_96/3893188529.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0241, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0348, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0134, dtype=torch.float64)\n",
      "percent loss:  3345.6234347841237\n",
      "testing ber:  0.4342105263157895\n",
      "1\n",
      "0.09203870245750914\n",
      "testing MSE:  tensor(0.0172, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0247, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0096, dtype=torch.float64)\n",
      "percent loss:  3464.2354426794263\n",
      "testing ber:  0.40405701754385964\n",
      "2\n",
      "0.06586545444232353\n",
      "testing MSE:  tensor(0.0082, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0092, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0071, dtype=torch.float64)\n",
      "percent loss:  3569.4425621749674\n",
      "testing ber:  0.30701754385964913\n",
      "3\n",
      "0.04767084300042467\n",
      "testing MSE:  tensor(0.0060, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0064, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0057, dtype=torch.float64)\n",
      "percent loss:  3623.0089090582596\n",
      "testing ber:  0.3223684210526316\n",
      "4\n",
      "0.0406869524455768\n",
      "testing MSE:  tensor(0.0052, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0055, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0050, dtype=torch.float64)\n",
      "percent loss:  3267.943525690722\n",
      "testing ber:  0.27028508771929827\n",
      "5\n",
      "0.03778461739420891\n",
      "testing MSE:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0040, dtype=torch.float64)\n",
      "percent loss:  2814.680844351941\n",
      "testing ber:  0.26644736842105265\n",
      "6\n",
      "0.0379659601467404\n",
      "testing MSE:  tensor(0.0049, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0041, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0057, dtype=torch.float64)\n",
      "percent loss:  2669.6646823630067\n",
      "testing ber:  0.2817982456140351\n",
      "7\n",
      "0.037563765441325114\n",
      "testing MSE:  tensor(0.0047, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0051, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0044, dtype=torch.float64)\n",
      "percent loss:  2750.3830292450743\n",
      "testing ber:  0.2768640350877193\n",
      "8\n",
      "0.03363781111275262\n",
      "testing MSE:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0036, dtype=torch.float64)\n",
      "percent loss:  2241.561540009906\n",
      "testing ber:  0.27905701754385964\n",
      "9\n",
      "0.03439244520949557\n",
      "testing MSE:  tensor(0.0041, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0035, dtype=torch.float64)\n",
      "percent loss:  2331.556881893161\n",
      "testing ber:  0.26973684210526316\n",
      "10\n",
      "0.03354521585192452\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  2307.811802951198\n",
      "testing ber:  0.2675438596491228\n",
      "11\n",
      "0.032592947971313554\n",
      "testing MSE:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0035, dtype=torch.float64)\n",
      "percent loss:  2392.9082329438556\n",
      "testing ber:  0.2669956140350877\n",
      "12\n",
      "0.03134518495186212\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1989.0671868997126\n",
      "testing ber:  0.2505482456140351\n",
      "13\n",
      "0.03156483786656184\n",
      "testing MSE:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0050, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0035, dtype=torch.float64)\n",
      "percent loss:  2186.0548630353737\n",
      "testing ber:  0.2576754385964912\n",
      "14\n",
      "0.030394918840140738\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0049, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1971.8567668268113\n",
      "testing ber:  0.2807017543859649\n",
      "15\n",
      "0.02996940968280777\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0042, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0034, dtype=torch.float64)\n",
      "percent loss:  2265.0352737879443\n",
      "testing ber:  0.24835526315789475\n",
      "16\n",
      "0.028721480947384175\n",
      "testing MSE:  tensor(0.0049, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0060, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0038, dtype=torch.float64)\n",
      "percent loss:  2401.7019198879193\n",
      "testing ber:  0.2631578947368421\n",
      "17\n",
      "0.028261797680975274\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1711.46671063005\n",
      "testing ber:  0.25219298245614036\n",
      "18\n",
      "0.02796351717428324\n",
      "testing MSE:  tensor(0.0046, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0056, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0036, dtype=torch.float64)\n",
      "percent loss:  2298.797451663386\n",
      "testing ber:  0.2598684210526316\n",
      "19\n",
      "0.02830869304214386\n",
      "testing MSE:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0047, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1761.9102760271794\n",
      "testing ber:  0.2571271929824561\n",
      "20\n",
      "0.028279764528207955\n",
      "testing MSE:  tensor(0.0051, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0069, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0034, dtype=torch.float64)\n",
      "percent loss:  2119.0460707433335\n",
      "testing ber:  0.26535087719298245\n",
      "21\n",
      "0.029671505232282142\n",
      "testing MSE:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0049, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0038, dtype=torch.float64)\n",
      "percent loss:  2044.9312417525548\n",
      "testing ber:  0.2631578947368421\n",
      "22\n",
      "0.027098384180522347\n",
      "testing MSE:  tensor(0.0033, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  2192.865888377896\n",
      "testing ber:  0.25164473684210525\n",
      "23\n",
      "0.02769944448261819\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0041, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0038, dtype=torch.float64)\n",
      "percent loss:  2097.2256275209006\n",
      "testing ber:  0.24780701754385964\n",
      "24\n",
      "0.02853039687776819\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0028, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0042, dtype=torch.float64)\n",
      "percent loss:  1958.2161844699895\n",
      "testing ber:  0.26260964912280704\n",
      "25\n",
      "0.027470651954570983\n",
      "testing MSE:  tensor(0.0034, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0034, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0033, dtype=torch.float64)\n",
      "percent loss:  2046.8438246224976\n",
      "testing ber:  0.25493421052631576\n",
      "26\n",
      "0.02974422419681511\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0045, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0034, dtype=torch.float64)\n",
      "percent loss:  1925.783046942183\n",
      "testing ber:  0.25109649122807015\n",
      "27\n",
      "0.027798081203264758\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0037, dtype=torch.float64)\n",
      "percent loss:  1797.8451176415142\n",
      "testing ber:  0.2675438596491228\n",
      "28\n",
      "0.026108977781172764\n",
      "testing MSE:  tensor(0.0027, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1764.1981382281967\n",
      "testing ber:  0.26096491228070173\n",
      "29\n",
      "0.026807004239093116\n",
      "testing MSE:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0052, dtype=torch.float64)\n",
      "percent loss:  1852.5717259181351\n",
      "testing ber:  0.27960526315789475\n",
      "30\n",
      "0.026450704892185775\n",
      "testing MSE:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0050, dtype=torch.float64)\n",
      "percent loss:  1776.1372463803643\n",
      "testing ber:  0.2719298245614035\n",
      "31\n",
      "0.027119219521100215\n",
      "testing MSE:  tensor(0.0042, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0049, dtype=torch.float64)\n",
      "percent loss:  1781.109326180084\n",
      "testing ber:  0.26918859649122806\n",
      "32\n",
      "0.025907599337478267\n",
      "testing MSE:  tensor(0.0051, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0063, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0039, dtype=torch.float64)\n",
      "percent loss:  1812.6163125998064\n",
      "testing ber:  0.2807017543859649\n",
      "33\n",
      "0.029261413922018194\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0042, dtype=torch.float64)\n",
      "percent loss:  1879.0025226497442\n",
      "testing ber:  0.24780701754385964\n",
      "34\n",
      "0.028278853427222434\n",
      "testing MSE:  tensor(0.0057, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0075, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0039, dtype=torch.float64)\n",
      "percent loss:  1667.5350021033705\n",
      "testing ber:  0.2730263157894737\n",
      "35\n",
      "0.026150966845849093\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0028, dtype=torch.float64)\n",
      "percent loss:  2144.220102830333\n",
      "testing ber:  0.2593201754385965\n",
      "36\n",
      "0.02595395866305904\n",
      "testing MSE:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0063, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0043, dtype=torch.float64)\n",
      "percent loss:  1859.4686256722057\n",
      "testing ber:  0.26096491228070173\n",
      "37\n",
      "0.025550501302201697\n",
      "testing MSE:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0051, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1933.7535170734916\n",
      "testing ber:  0.2735745614035088\n",
      "38\n",
      "0.027856759231616842\n",
      "testing MSE:  tensor(0.0052, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0065, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0039, dtype=torch.float64)\n",
      "percent loss:  2135.321106981682\n",
      "testing ber:  0.26206140350877194\n",
      "39\n",
      "0.025434921129032017\n",
      "testing MSE:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0049, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0030, dtype=torch.float64)\n",
      "percent loss:  1955.2784557536997\n",
      "testing ber:  0.26151315789473684\n",
      "40\n",
      "0.02465571455181913\n",
      "testing MSE:  tensor(0.0039, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1891.9967850004641\n",
      "testing ber:  0.26096491228070173\n",
      "41\n",
      "0.025520786207090033\n",
      "testing MSE:  tensor(0.0024, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1481.8213095453011\n",
      "testing ber:  0.21710526315789475\n",
      "42\n",
      "0.024497571203144306\n",
      "testing MSE:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0041, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0047, dtype=torch.float64)\n",
      "percent loss:  1773.7404963766792\n",
      "testing ber:  0.2461622807017544\n",
      "43\n",
      "0.026028933181883172\n",
      "testing MSE:  tensor(0.0030, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0029, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  2254.3774425783686\n",
      "testing ber:  0.22039473684210525\n",
      "44\n",
      "0.026491197628622995\n",
      "testing MSE:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0027, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0060, dtype=torch.float64)\n",
      "percent loss:  1699.8693075456274\n",
      "testing ber:  0.24232456140350878\n",
      "45\n",
      "0.026091137712702474\n",
      "testing MSE:  tensor(0.0058, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0058, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0059, dtype=torch.float64)\n",
      "percent loss:  1743.0801897844851\n",
      "testing ber:  0.26918859649122806\n",
      "46\n",
      "0.025659517939896025\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0036, dtype=torch.float64)\n",
      "percent loss:  1656.5798438970746\n",
      "testing ber:  0.26644736842105265\n",
      "47\n",
      "0.025791672642957023\n",
      "testing MSE:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0044, dtype=torch.float64)\n",
      "percent loss:  1687.7960692848242\n",
      "testing ber:  0.27850877192982454\n",
      "48\n",
      "0.02755939324406233\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0032, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0044, dtype=torch.float64)\n",
      "percent loss:  2025.1079864574772\n",
      "testing ber:  0.24780701754385964\n",
      "49\n",
      "0.02618615330256363\n",
      "testing MSE:  tensor(0.0059, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0056, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0063, dtype=torch.float64)\n",
      "percent loss:  2228.357800596102\n",
      "testing ber:  0.2631578947368421\n",
      "50\n",
      "0.025414916944313557\n",
      "testing MSE:  tensor(0.0047, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0041, dtype=torch.float64)\n",
      "percent loss:  2174.920005503185\n",
      "testing ber:  0.2412280701754386\n",
      "51\n",
      "0.02356119658996133\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0045, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1851.2138577270298\n",
      "testing ber:  0.2532894736842105\n",
      "52\n",
      "0.024858411223171874\n",
      "testing MSE:  tensor(0.0050, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0046, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0053, dtype=torch.float64)\n",
      "percent loss:  1932.8478370864882\n",
      "testing ber:  0.26480263157894735\n",
      "53\n",
      "0.024147402653668788\n",
      "testing MSE:  tensor(0.0054, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0052, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0056, dtype=torch.float64)\n",
      "percent loss:  2296.88759414074\n",
      "testing ber:  0.2807017543859649\n",
      "54\n",
      "0.023966337772125892\n",
      "testing MSE:  tensor(0.0050, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0060, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0039, dtype=torch.float64)\n",
      "percent loss:  2107.118540618083\n",
      "testing ber:  0.24451754385964913\n",
      "55\n",
      "0.025025142009984305\n",
      "testing MSE:  tensor(0.0033, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0031, dtype=torch.float64)\n",
      "percent loss:  1845.3088578601698\n",
      "testing ber:  0.24177631578947367\n",
      "56\n",
      "0.02528004392862637\n",
      "testing MSE:  tensor(0.0046, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0061, dtype=torch.float64)\n",
      "percent loss:  2065.804222259615\n",
      "testing ber:  0.2675438596491228\n",
      "57\n",
      "0.024134366673992037\n",
      "testing MSE:  tensor(0.0061, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0053, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0070, dtype=torch.float64)\n",
      "percent loss:  1979.7029216938745\n",
      "testing ber:  0.2746710526315789\n",
      "58\n",
      "0.023781193241952582\n",
      "testing MSE:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0057, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0029, dtype=torch.float64)\n",
      "percent loss:  1604.9332907429023\n",
      "testing ber:  0.2642543859649123\n",
      "59\n",
      "0.025106509850221746\n",
      "testing MSE:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0059, dtype=torch.float64)\n",
      "percent loss:  2054.776897262435\n",
      "testing ber:  0.22697368421052633\n",
      "60\n",
      "0.024150746884418928\n",
      "testing MSE:  tensor(0.0048, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0061, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0035, dtype=torch.float64)\n",
      "percent loss:  2134.210626858582\n",
      "testing ber:  0.26918859649122806\n",
      "61\n",
      "0.024269092402004814\n",
      "testing MSE:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0048, dtype=torch.float64)\n",
      "percent loss:  2468.423185684092\n",
      "testing ber:  0.24067982456140352\n",
      "62\n",
      "0.02454500229276241\n",
      "testing MSE:  tensor(0.0075, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0060, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0090, dtype=torch.float64)\n",
      "percent loss:  1905.2099336151562\n",
      "testing ber:  0.29660087719298245\n",
      "63\n",
      "0.025725706232751302\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0024, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0052, dtype=torch.float64)\n",
      "percent loss:  2122.530930649297\n",
      "testing ber:  0.2505482456140351\n",
      "64\n",
      "0.023819202289698607\n",
      "testing MSE:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  1953.4578102141334\n",
      "testing ber:  0.23026315789473684\n",
      "65\n",
      "0.02320525592113746\n",
      "testing MSE:  tensor(0.0087, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0062, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0112, dtype=torch.float64)\n",
      "percent loss:  2150.130195549298\n",
      "testing ber:  0.2944078947368421\n",
      "66\n",
      "0.024519798940325035\n",
      "testing MSE:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0050, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  2335.2722884223713\n",
      "testing ber:  0.2412280701754386\n",
      "67\n",
      "0.02409519715868729\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainloader, testloader, model, DNN_model, rc, lr, nb_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(local_loss)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_loss)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_loader, net_snn, net_dnn, rc, num_frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m input1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input1)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input2)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet_snn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m net_dnn(output, input1, input2)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m all_output\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, spike):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 37\u001b[0m         spike \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spike\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/block/base.py:508\u001b[0m, in \u001b[0;36mAbstractDense.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapse\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\n\u001b[1;32m    507\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapse(x)\n\u001b[0;32m--> 508\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_shift \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     x \u001b[38;5;241m=\u001b[39m delay(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:433\u001b[0m, in \u001b[0;36mNeuron.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the full response of the neuron instance to an input.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    The input shape must match with the neuron shape. For the first time,\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    the neuron shape is determined from the input automatically.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     _, voltage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike(voltage)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:351\u001b[0m, in \u001b[0;36mNeuron.dynamics\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamp()\n\u001b[0;32m--> 351\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[43mleaky_integrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(current)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:93\u001b[0m, in \u001b[0;36mdynamics\u001b[0;34m(input, decay, state, w_scale, threshold, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m     state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_LIDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     output \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mdynamics(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcontiguous(), decay\u001b[38;5;241m.\u001b[39mcontiguous(), state\u001b[38;5;241m.\u001b[39mcontiguous(),\n\u001b[1;32m     97\u001b[0m         threshold, w_scale\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:129\u001b[0m, in \u001b[0;36m_LIDynamics.forward\u001b[0;34m(ctx, input, decay, state, threshold, w_scale)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_li_dynamics_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _LIDynamics\u001b[38;5;241m.\u001b[39mDEBUG \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         _output, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mfwd(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale\n\u001b[1;32m    137\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:221\u001b[0m, in \u001b[0;36m_li_dynamics_fwd\u001b[0;34m(input, decay, state, threshold, w_scale, dtype)\u001b[0m\n\u001b[1;32m    218\u001b[0m threshold \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m w_scale\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 221\u001b[0m     output_new \u001b[38;5;241m=\u001b[39m \u001b[43mright_shift_to_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_old\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    222\u001b[0m         (w_scale \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, n])\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    224\u001b[0m         spike_new \u001b[38;5;241m=\u001b[39m (output_new \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/utils/int_utils.py:31\u001b[0m, in \u001b[0;36mright_shift_to_zero\u001b[0;34m(x, bits)\u001b[0m\n\u001b[1;32m     29\u001b[0m x_sign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# return x_sign * (x_sign * x >> bits) # This seems to return torch.int64!\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (x_sign \u001b[38;5;241m*\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mx_sign\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbits\u001b[49m))\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, net_snn, net_dnn, rc, lr=1e-3, nb_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac761138-0e7d-42b0-a0ed-c75ab87036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219/3403701246.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_219/3403701246.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_219/3403701246.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_219/3403701246.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE RC:  tensor(0.0051, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0036, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "RC_train_time = np.load(\"gt_train_pred.npy\")\n",
    "print(\"train MSE: \", torch.nn.MSELoss()(torch.tensor(RC_train_time), torch.tensor(train_label)))\n",
    "def test_train_both(train_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in train_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    print(\"train MSE RC: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(RC_train_time)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(train_label)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(train_label), torch.tensor(RC_train_time)))\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_train_both(train_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808d7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_snn.export_hdf5('./net_snn.net')\n",
    "torch.save(net_dnn.state_dict(), './net_dnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "898cb37e-9af7-45f8-a3e2-8ddbd0db0dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/229205384.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/229205384.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/229205384.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/229205384.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7521, 2]) torch.Size([7521, 2])\n",
      "all_loss:  tensor(0.0024)\n",
      "no first 330 loss:  tensor(0.0014)\n"
     ]
    }
   ],
   "source": [
    "temp_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test_MSE(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "    \n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "    \n",
    "    all_output = torch.tensor(np.concatenate(all_output, axis=0)).detach()\n",
    "    labels = torch.tensor(np.concatenate(labels, axis=0)).detach()\n",
    "    print(all_output.shape, labels.shape)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    print(\"all_loss: \", loss_fn(all_output, labels))\n",
    "    print(\"no first 330 loss: \", loss_fn(all_output[330:, :], labels[330:, :]))\n",
    "\n",
    "test_MSE(temp_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7acff8c-50b2-4bd2-93f8-b3106dddedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/3202473027.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/3202473027.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/3202473027.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/3202473027.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18902153558052434\n"
     ]
    }
   ],
   "source": [
    "all_output = []\n",
    "inputs = []\n",
    "labels = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    ber = rc.my_test(all_output)\n",
    "    print(ber)\n",
    "    \n",
    "test(test_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ee219a-952a-4395-b2a9-db85d18f17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        ...,\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "A1 = 8 * torch.ones((128, 8))\n",
    "A2 = torch.ones((128, 1))\n",
    "print(A1 + A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eebf40-ab07-4dda-9afb-3caa814cefa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
