{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138b6027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "\n",
    "from Loss import ber_loss\n",
    "\n",
    "from DFRSystem import *\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import slayer from lava-dl\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "import IPython.display as display\n",
    "from matplotlib import animation\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.__version__\n",
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4) (7521, 4)\n",
      "test_input_diff:  tensor(4.2689e-10, dtype=torch.float64)\n",
      "train_input_diff:  tensor(4.3102e-11, dtype=torch.float64)\n",
      "train_label_diff:  tensor(0., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [55]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 1\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "RC_test_input = np.load('gt_test_input_1.npy')\n",
    "RC_train_input = np.load('gt_train_input_1.npy')\n",
    "RC_train_label = np.load('gt_train_label_1.npy')\n",
    "\n",
    "print(RC_test_input.shape, test_input.shape)\n",
    "print(\"test_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_test_input), torch.tensor(test_input)))\n",
    "\n",
    "print(\"train_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_input), torch.tensor(train_input)))\n",
    "\n",
    "print(\"train_label_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_label), torch.tensor(train_label)))\n",
    "\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std\n",
    "train_label = 1.0 * train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a8c5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7521, 4)\n",
      "(7521, 4)\n",
      "(7521, 2)\n",
      "(89, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7395dfe-dc16-458e-989e-b39bfcc397e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1         2         3         4\n",
      "0  0.004539  0.004539 -1.879304  0.267193\n",
      "1 -1.879304  0.267193  0.806606 -5.120261\n",
      "2  0.806606 -5.120261  2.432891  1.354990\n",
      "3  2.432891  1.354990  0.266532  5.131409\n",
      "4  0.266532  5.131409  0.007632  3.781927\n",
      "             1         2         3         4\n",
      "6001 -0.662524  0.675905 -0.212320 -1.234322\n",
      "6002 -0.212320 -1.234322 -0.929190 -0.694511\n",
      "6003 -0.929190 -0.694511 -1.298258  0.320076\n",
      "6004 -1.298258  0.320076  0.261380 -0.844621\n",
      "6005  0.261380 -0.844621  0.519746  0.138324\n",
      "(6001, 4)\n",
      "(1520, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def pre_processing(train_input, train_label):\n",
    "    idx_p = 10\n",
    "    begin = 0 # N_total_frame * N_sync_frame\n",
    "    \n",
    "    # label index for data\n",
    "    train_input_df = pd.DataFrame(train_input, columns = ['1','2', '3', '4'])\n",
    "    #train_input_df['L1_idx'] = train_input_df.index % idx_p\n",
    "\n",
    "    # label index for label\n",
    "    train_label_df = pd.DataFrame(train_label, columns = ['L1','L2'])\n",
    "    train_label_df['L1_idx'] = train_label_df.index % idx_p\n",
    "    \n",
    "    # split training and testing data\n",
    "    test_input_df, test_label_df = train_input_df.iloc[75* 80 + 1:, :], train_label_df.iloc[75* 80 + 1:, :]\n",
    "    train_input_df, train_label_df = train_input_df.iloc[:75* 80 + 1, :], train_label_df.iloc[:75* 80 + 1, :]\n",
    "\n",
    "    # group by \n",
    "    #mapping = train_label_df.loc[begin:, :].groupby(by='L1_idx').mean().reset_index().loc[:, ['L1', 'L2', 'L1_idx']] \n",
    "    \n",
    "    #train_input_df = pd.merge(train_input_df, mapping, how='left', on='L1_idx')\n",
    "\n",
    "    #train_input_df = pd.get_dummies(train_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    train_input_df = train_input_df.loc[begin:, :]\n",
    "\n",
    "\n",
    "    print(train_input_df.head())\n",
    "    \n",
    "    # testing data\n",
    "    # group by\n",
    "    #test_input_df = test_input_df.merge(mapping, how = 'left', on='L1_idx')\n",
    "\n",
    "    #test_input_df = pd.get_dummies(test_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    print(test_input_df.head())\n",
    "\n",
    "    train_input = train_input_df.to_numpy()\n",
    "    test_input = test_input_df.to_numpy()\n",
    "    \n",
    "    train_label = train_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    test_label = test_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    \n",
    "    print(train_input.shape)\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    \n",
    "    return train_input, train_label, test_input, test_label\n",
    "\n",
    "train_input, train_label, test_input, test_label = pre_processing(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0acdc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n",
      "(24, 100)\n",
      "(1,)\n",
      "(24,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 6\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, RegTorchSeasonalitySpikingDataset, RegSpikingDataset, RegTorchSpikingDataset, RegTorchSeasonalityLinearSpikingDataset\n",
    "train_data = RegTorchSeasonalityLinearSpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "test_data = RegTorchSeasonalityLinearSpikingDataset(test_input, test_label, nb_inputs, nb_steps)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daf4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "       # neuron_params = {\n",
    "       #         'threshold'     : 0.1,\n",
    "       #         'current_decay' : 1,\n",
    "       #         'voltage_decay' : 0.1,\n",
    "       #         'requires_grad' : True,     \n",
    "       #     }\n",
    "        #neuron_params_drop = {**neuron_params, 'dropout' : slayer.neuron.Dropout(p=0.05),}\n",
    "        neuron_params = {\n",
    "                'threshold'     : 1.25,\n",
    "                'current_decay' : 0.25,\n",
    "                'voltage_decay' : 0.03,\n",
    "                'tau_grad'      : 0.03,\n",
    "                'scale_grad'    : 100,\n",
    "                'requires_grad' : True,     \n",
    "            }\n",
    "        \n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "                #slayer.block.cuba.Input(neuron_params),\n",
    "                slayer.block.cuba.Recurrent(neuron_params, input_size, 8, weight_norm=True, delay=True),\n",
    "                slayer.block.cuba.Dense(neuron_params, 8, 1, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 64, 128, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 128, output_size, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, input_size, 64, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 64, 128, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 128, output_size, weight_scale=2, weight_norm=True)\n",
    "                #slayer.block.cuba.Recurrent(cuba_params, 100, 50),\n",
    "                #slayer.block.cuba.KWTA(cuba_params, 50, 50, num_winners=5)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, spike):\n",
    "        for block in self.blocks:\n",
    "            spike = block(spike)\n",
    "        return spike\n",
    "\n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "\n",
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2)\n",
    "        self.fc2 = nn.Linear(16 + 1 + 24, 8)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "        #self.fc3 = nn.Linear(128, 128)\n",
    "        #self.fc4 = nn.Linear(128, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self,x, x1, x2):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = torch.cat((x, x2), axis=1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        #x = self.fc1(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc3(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3584c-e278-49a0-b6cc-8c806b572060",
   "metadata": {},
   "source": [
    "# Teacher Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c6883f91-5aaa-46c8-bacc-299e86a0a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=1, num_layers=1, batch_first=True, bias=False)\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=1, num_layers=1, batch_first=True, bias=False)\n",
    "        self.rnn.weight_ih_l0.requires_grad_(False)\n",
    "        self.rnn.weight_hh_l0.requires_grad_(False)\n",
    "        self.fc1 = nn.Linear(16, 8)\n",
    "        self.fc2 = nn.Linear(1 + 6 * 4, 2)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_x, _ = self.rnn(x)\n",
    "        rnn_x = rnn_x[:, -1, :]\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = torch.cat((x, rnn_x), axis=1)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.act(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = self.act(x)\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "torch.zeros(x.size(0), node_size).to(device)\n",
    "net_rc = TOriFloatDFRSystem(n_hidden=8, n_fc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f1084390",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_snn = Network(nb_inputs * 4, 2).to(device)\n",
    "net_dnn = DNNNetwork(1 * 100 + nb_inputs * 4 + 0 + 0 * nb_inputs, 2).to(device)\n",
    "\n",
    "net_lstm = LSTMNet(4, 2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "db8441bd-8c48-4451-a52d-88763313aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2663874445.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_158/2663874445.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_158/2663874445.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_158/2663874445.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.1710, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.2646, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0774, dtype=torch.float64)\n",
      "percent loss:  12735.879078848802\n",
      "testing ber:  0.5252192982456141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2663874445.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_158/2663874445.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_158/2663874445.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_158/2663874445.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.4330, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.2128, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.6533, dtype=torch.float64)\n",
      "percent loss:  27246.08719022878\n",
      "testing ber:  0.5427631578947368\n"
     ]
    }
   ],
   "source": [
    "def test(test_loader, net_snn, net_dnn, rc, num_frame = 19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        \n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    print(\"testing MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    print(\"testing MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    print(\"testing MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    print(\"percent loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing ber: \", rc.my_new_test(predict_time, target_time))\n",
    "\n",
    "\n",
    "def test_teacher(test_loader, model, rc, nb_inputs, num_frame=19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "        \n",
    "        input2 = input2.view(input2.shape[0], nb_inputs, 4)\n",
    "        \n",
    "        output = model(input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    print(\"testing MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    print(\"testing MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    print(\"testing MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    print(\"percent loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing ber: \", rc.my_new_test(predict_time, target_time))\n",
    "\n",
    "test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "test_teacher(test_loader, net_lstm, rc, nb_inputs, num_frame=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c79d3c6a-e9de-4838-b114-9c9c95972ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn(trainloader, testloader, net, rc, nb_inputs, lr=2e-3, nb_epochs=10):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9,0.999), weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    loss_hist = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        loss_hist = []\n",
    "        for x1_local, x2_local, x3_local, y_local in trainloader:\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            x3_local = x3_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # lstm model\n",
    "            x3_local = x3_local.view(x3_local.shape[0], nb_inputs, 4)\n",
    "            output = net(x3_local)\n",
    "            \n",
    "            loss = loss_fn(output, y_local)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "        print(np.mean(loss_hist))\n",
    "        \n",
    "        test_teacher(test_loader, net, rc, nb_inputs, num_frame=19)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b3c9680-0bfd-4b4a-a685-c2ae4a85318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.1696589042214637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2663874445.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_158/2663874445.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_158/2663874445.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_158/2663874445.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0028, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0034, dtype=torch.float64)\n",
      "percent loss:  2098.7779028374657\n",
      "testing ber:  0.20175438596491227\n",
      "1\n",
      "0.06365903145930868\n",
      "testing MSE:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0019, dtype=torch.float64)\n",
      "percent loss:  2350.4470126920965\n",
      "testing ber:  0.12280701754385964\n",
      "2\n",
      "0.051987762582745956\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  869.1300416084684\n",
      "testing ber:  0.17105263157894737\n",
      "3\n",
      "0.059541984243278806\n",
      "testing MSE:  tensor(0.0030, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1989.026201540289\n",
      "testing ber:  0.1337719298245614\n",
      "4\n",
      "0.06062438350884204\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  749.5634783917309\n",
      "testing ber:  0.16776315789473684\n",
      "5\n",
      "0.05641207812314338\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  2038.4423101020866\n",
      "testing ber:  0.15076754385964913\n",
      "6\n",
      "0.06860021684080997\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  674.8911709297223\n",
      "testing ber:  0.14528508771929824\n",
      "7\n",
      "0.05635058091200413\n",
      "testing MSE:  tensor(0.0027, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0032, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0023, dtype=torch.float64)\n",
      "percent loss:  1648.7272054479274\n",
      "testing ber:  0.14418859649122806\n",
      "8\n",
      "0.0662379023876596\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0024, dtype=torch.float64)\n",
      "percent loss:  1119.5057358382753\n",
      "testing ber:  0.12828947368421054\n",
      "9\n",
      "0.06562862751331736\n",
      "testing MSE:  tensor(0.0025, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0028, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1528.1299346758628\n",
      "testing ber:  0.15515350877192982\n",
      "10\n",
      "0.06315479193754653\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1228.247869117587\n",
      "testing ber:  0.14418859649122806\n",
      "11\n",
      "0.06182148051943551\n",
      "testing MSE:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  1215.4183955187073\n",
      "testing ber:  0.14692982456140352\n",
      "12\n",
      "0.05815155942864875\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1255.355679555224\n",
      "testing ber:  0.11842105263157894\n",
      "13\n",
      "0.07321408339478869\n",
      "testing MSE:  tensor(0.0025, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0033, dtype=torch.float64)\n",
      "percent loss:  1117.7045252642845\n",
      "testing ber:  0.15570175438596492\n",
      "14\n",
      "0.058732271432242494\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0029, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0012, dtype=torch.float64)\n",
      "percent loss:  1299.6248605106055\n",
      "testing ber:  0.12390350877192982\n",
      "15\n",
      "0.07380633840852595\n",
      "testing MSE:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0034, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0035, dtype=torch.float64)\n",
      "percent loss:  1124.6519362512618\n",
      "testing ber:  0.16666666666666666\n",
      "16\n",
      "0.06129292418506551\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1160.5951519707135\n",
      "testing ber:  0.1025219298245614\n",
      "17\n",
      "0.07664156879516358\n",
      "testing MSE:  tensor(0.0034, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0032, dtype=torch.float64)\n",
      "percent loss:  1408.428271477234\n",
      "testing ber:  0.1425438596491228\n",
      "18\n",
      "0.058655894183098\n",
      "testing MSE:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1242.0611621889325\n",
      "testing ber:  0.11787280701754387\n",
      "19\n",
      "0.07327186343993278\n",
      "testing MSE:  tensor(0.0032, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0044, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1169.0310519841935\n",
      "testing ber:  0.11951754385964912\n",
      "20\n",
      "0.058615738288202185\n",
      "testing MSE:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0023, dtype=torch.float64)\n",
      "percent loss:  1269.3604357105448\n",
      "testing ber:  0.12390350877192982\n",
      "21\n",
      "0.08453664504625696\n",
      "testing MSE:  tensor(0.0030, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0035, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0024, dtype=torch.float64)\n",
      "percent loss:  1309.022106109226\n",
      "testing ber:  0.12280701754385964\n",
      "22\n",
      "0.05616527795791626\n",
      "testing MSE:  tensor(0.0025, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0024, dtype=torch.float64)\n",
      "percent loss:  1400.4581659134667\n",
      "testing ber:  0.13541666666666666\n",
      "23\n",
      "0.08057448335308978\n",
      "testing MSE:  tensor(0.0024, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0026, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0023, dtype=torch.float64)\n",
      "percent loss:  1259.0052577733477\n",
      "testing ber:  0.09978070175438597\n",
      "24\n",
      "0.05580693693395625\n",
      "testing MSE:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0032, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1379.8839673592909\n",
      "testing ber:  0.15789473684210525\n",
      "25\n",
      "0.07676655034277033\n",
      "testing MSE:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  1104.7223780211398\n",
      "testing ber:  0.12280701754385964\n",
      "26\n",
      "0.05821247434520975\n",
      "testing MSE:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1401.5817282836958\n",
      "testing ber:  0.15296052631578946\n",
      "27\n",
      "0.08028516779713174\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0038, dtype=torch.float64)\n",
      "percent loss:  1844.7975548548986\n",
      "testing ber:  0.14583333333333334\n",
      "28\n",
      "0.05737367139614009\n",
      "testing MSE:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0021, dtype=torch.float64)\n",
      "percent loss:  1339.298542930513\n",
      "testing ber:  0.14364035087719298\n",
      "29\n",
      "0.07581011352545404\n",
      "testing MSE:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0033, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0029, dtype=torch.float64)\n",
      "percent loss:  1552.4367199063522\n",
      "testing ber:  0.12116228070175439\n",
      "30\n",
      "0.05872861977587355\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0024, dtype=torch.float64)\n",
      "percent loss:  1516.8455763689824\n",
      "testing ber:  0.12938596491228072\n",
      "31\n",
      "0.07647989591226932\n",
      "testing MSE:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0023, dtype=torch.float64)\n",
      "percent loss:  1414.4921676257986\n",
      "testing ber:  0.11732456140350878\n",
      "32\n",
      "0.05704668088954814\n",
      "testing MSE:  tensor(0.0025, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0030, dtype=torch.float64)\n",
      "percent loss:  1410.7597794793135\n",
      "testing ber:  0.125\n",
      "33\n",
      "0.07605224122550894\n",
      "testing MSE:  tensor(0.0038, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0050, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  1772.8648824839177\n",
      "testing ber:  0.13103070175438597\n",
      "34\n",
      "0.05800085728789898\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0023, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1283.4255157954312\n",
      "testing ber:  0.13432017543859648\n",
      "35\n",
      "0.07373484881951455\n",
      "testing MSE:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0040, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0032, dtype=torch.float64)\n",
      "percent loss:  1772.2727088792587\n",
      "testing ber:  0.1299342105263158\n",
      "36\n",
      "0.055685765109956264\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1245.9039351620706\n",
      "testing ber:  0.14967105263157895\n",
      "37\n",
      "0.07546671531460386\n",
      "testing MSE:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0046, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0029, dtype=torch.float64)\n",
      "percent loss:  1529.0730184935874\n",
      "testing ber:  0.1206140350877193\n",
      "38\n",
      "0.05815611327899263\n",
      "testing MSE:  tensor(0.0022, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0024, dtype=torch.float64)\n",
      "percent loss:  1311.2176474914656\n",
      "testing ber:  0.14035087719298245\n",
      "39\n",
      "0.0778822993185926\n",
      "testing MSE:  tensor(0.0036, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0043, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0028, dtype=torch.float64)\n",
      "percent loss:  1524.0156128189858\n",
      "testing ber:  0.13267543859649122\n",
      "40\n",
      "0.05679133962443535\n",
      "testing MSE:  tensor(0.0021, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0029, dtype=torch.float64)\n",
      "percent loss:  1313.1513472208937\n",
      "testing ber:  0.12116228070175439\n",
      "41\n",
      "0.07314098487667581\n",
      "testing MSE:  tensor(0.0033, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0041, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0026, dtype=torch.float64)\n",
      "percent loss:  1590.7347966808225\n",
      "testing ber:  0.12609649122807018\n",
      "42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36mtrain_dnn\u001b[0;34m(trainloader, testloader, net, rc, nb_inputs, lr, nb_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     10\u001b[0m loss_hist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x1_local, x2_local, x3_local, y_local \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[1;32m     12\u001b[0m     x1_local \u001b[38;5;241m=\u001b[39m x1_local\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     x2_local \u001b[38;5;241m=\u001b[39m x2_local\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Research/RC_wifi/dataset.py:206\u001b[0m, in \u001b[0;36mRegTorchSeasonalityLinearSpikingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    204\u001b[0m temp_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_data[i][:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m    205\u001b[0m temp_tensor \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m X1[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 206\u001b[0m temp_result \u001b[38;5;241m=\u001b[39m \u001b[43mbernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(temp_result\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    208\u001b[0m X_p\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_data[i][:])\n",
      "File \u001b[0;32m~/Research/RC_wifi/encoder.py:57\u001b[0m, in \u001b[0;36mbernoulli\u001b[0;34m(datum, time, dt, device, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     spikes \u001b[38;5;241m=\u001b[39m spikes\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mshape)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     spikes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbernoulli(\u001b[43mmax_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     58\u001b[0m     spikes \u001b[38;5;241m=\u001b[39m spikes\u001b[38;5;241m.\u001b[39mview(time, \u001b[38;5;241m*\u001b[39mshape)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m spikes\u001b[38;5;241m.\u001b[39mbyte()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dnn(train_loader, test_loader, net_lstm, rc, nb_inputs, lr=1e-2, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2da4b5ed-5638-4d1f-b4d5-a738c675f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_loss(teach_output, student_output, alpha, target):\n",
    "    # student loss 1\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    loss1 = loss_fn(student_output, target)\n",
    "    loss2 = loss_fn(student_output, teach_output)\n",
    "    loss = (1 - alpha) * loss1 + alpha * loss2\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mutual_train(trainloader, testloader, net_snn, net_dnn, net_teacher, nb_inputs, lr=2e-3, nb_epochs=10):\n",
    "    params = list(net_snn.parameters()) + list(net_dnn.parameters())\n",
    "    optimizer_student = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    optimizer_teacher = torch.optim.Adam(net_teacher.parameters(), lr=lr, betas=(0.9,0.999))\n",
    "    scheduler_student = torch.optim.lr_scheduler.StepLR(optimizer_student, step_size=100, gamma=0.1)\n",
    "    scheduler_teacher = torch.optim.lr_scheduler.StepLR(optimizer_teacher, step_size=100, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.SmoothL1Loss()\n",
    "    loss_hist = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        loss_hist = []\n",
    "        for x1_local, x2_local, x3_local, y_local in trainloader:\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            x3_local = x3_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            optimizer_student.zero_grad()\n",
    "            optimizer_teacher.zero_grad()\n",
    "            \n",
    "            # snn model \n",
    "            output = net_snn(x1_local)\n",
    "            output = net_dnn(output, x2_local, x3_local)\n",
    "            \n",
    "            # lstm model\n",
    "            x3_local = x3_local.view(x3_local.shape[0], nb_inputs, 4)\n",
    "            teacher_output = net_teacher(x3_local)\n",
    "            \n",
    "            student_loss = mutual_loss(teacher_output.detach(), output, alpha=0.1, target=y_local)\n",
    "            teacher_loss = mutual_loss(output.detach(), teacher_output, alpha=0.1, target=y_local)\n",
    "            student_loss.backward()\n",
    "            teacher_loss.backward()\n",
    "            optimizer_student.step()\n",
    "            optimizer_teacher.step()\n",
    "            loss_hist.append(student_loss.item() + teacher_loss.item())\n",
    "        print(np.mean(loss_hist))\n",
    "        \n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        test_teacher(test_loader, net_teacher, rc, nb_inputs, num_frame=19)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aac16670-6fb3-40df-84d8-05708ff0350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.05568951092898212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2663874445.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_158/2663874445.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_158/2663874445.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_158/2663874445.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0022, dtype=torch.float64)\n",
      "percent loss:  1464.139161515669\n",
      "testing ber:  0.11677631578947369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158/2663874445.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_158/2663874445.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_158/2663874445.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_158/2663874445.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0010, dtype=torch.float64)\n",
      "percent loss:  954.9820594109614\n",
      "testing ber:  0.12280701754385964\n",
      "1\n",
      "0.06821360601548185\n",
      "testing MSE:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0010, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0012, dtype=torch.float64)\n",
      "percent loss:  1093.8412849571953\n",
      "testing ber:  0.11293859649122807\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  939.6628155931152\n",
      "testing ber:  0.13267543859649122\n",
      "2\n",
      "0.06607823975463496\n",
      "testing MSE:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0011, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0011, dtype=torch.float64)\n",
      "percent loss:  1162.1435620529694\n",
      "testing ber:  0.11074561403508772\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  813.3593113943303\n",
      "testing ber:  0.12171052631578948\n",
      "3\n",
      "0.06027321755251986\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0013, dtype=torch.float64)\n",
      "percent loss:  1234.742746368094\n",
      "testing ber:  0.1162280701754386\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  897.0590500311407\n",
      "testing ber:  0.13980263157894737\n",
      "4\n",
      "0.059649840413414416\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1309.6139606114616\n",
      "testing ber:  0.12006578947368421\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  928.0871397551978\n",
      "testing ber:  0.12664473684210525\n",
      "5\n",
      "0.06235573587423943\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1297.459694108797\n",
      "testing ber:  0.1162280701754386\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1075.9397704496487\n",
      "testing ber:  0.12828947368421054\n",
      "6\n",
      "0.06275133477484292\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1304.7335629571578\n",
      "testing ber:  0.11732456140350878\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  978.1418054823517\n",
      "testing ber:  0.12225877192982457\n",
      "7\n",
      "0.06020295780469129\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1358.270345785933\n",
      "testing ber:  0.11513157894736842\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  916.7620386119265\n",
      "testing ber:  0.12390350877192982\n",
      "8\n",
      "0.05679198340611889\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1322.689136756795\n",
      "testing ber:  0.11293859649122807\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  979.6515652699641\n",
      "testing ber:  0.12774122807017543\n",
      "9\n",
      "0.05759483187439594\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1328.7147278608313\n",
      "testing ber:  0.10910087719298246\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  907.6427698138675\n",
      "testing ber:  0.12609649122807018\n",
      "10\n",
      "0.05778760243048693\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1333.3693377518362\n",
      "testing ber:  0.10964912280701754\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1034.1991796571417\n",
      "testing ber:  0.12445175438596491\n",
      "11\n",
      "0.056998927483057724\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0014, dtype=torch.float64)\n",
      "percent loss:  1380.7872839993204\n",
      "testing ber:  0.10526315789473684\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1011.3773060821364\n",
      "testing ber:  0.12335526315789473\n",
      "12\n",
      "0.05617679187909086\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1360.9835138407157\n",
      "testing ber:  0.10800438596491228\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  925.3173971157787\n",
      "testing ber:  0.12280701754385964\n",
      "13\n",
      "0.055239350713313894\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1357.712495579644\n",
      "testing ber:  0.10471491228070176\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  967.7767955803996\n",
      "testing ber:  0.13267543859649122\n",
      "14\n",
      "0.057766700757944836\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1344.7962652961294\n",
      "testing ber:  0.10526315789473684\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  914.8353919020728\n",
      "testing ber:  0.12171052631578948\n",
      "15\n",
      "0.05907111549551817\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1332.1290573556537\n",
      "testing ber:  0.10361842105263158\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  850.6463501216776\n",
      "testing ber:  0.13432017543859648\n",
      "16\n",
      "0.05511435327377725\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1357.0852501607374\n",
      "testing ber:  0.10416666666666667\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1203.789345637166\n",
      "testing ber:  0.13048245614035087\n",
      "17\n",
      "0.05771618113516176\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1369.1405529750589\n",
      "testing ber:  0.10471491228070176\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  871.2953348432217\n",
      "testing ber:  0.13596491228070176\n",
      "18\n",
      "0.058424328057531345\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1355.2273668546268\n",
      "testing ber:  0.10087719298245613\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1132.217894933682\n",
      "testing ber:  0.13157894736842105\n",
      "19\n",
      "0.05499264768304977\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1361.1095841471945\n",
      "testing ber:  0.10142543859649122\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1013.124147493126\n",
      "testing ber:  0.13103070175438597\n",
      "20\n",
      "0.058491921547721044\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1391.751980281745\n",
      "testing ber:  0.10197368421052631\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  992.2160492186281\n",
      "testing ber:  0.13596491228070176\n",
      "21\n",
      "0.0609676695448604\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1343.0694638244513\n",
      "testing ber:  0.10087719298245613\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1054.8700628692438\n",
      "testing ber:  0.13432017543859648\n",
      "22\n",
      "0.05900730863411693\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1405.4925722475984\n",
      "testing ber:  0.09978070175438597\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  979.8413153573653\n",
      "testing ber:  0.13157894736842105\n",
      "23\n",
      "0.053262319911192076\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1384.850550215947\n",
      "testing ber:  0.0981359649122807\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0009, dtype=torch.float64)\n",
      "percent loss:  1161.0883777479544\n",
      "testing ber:  0.14309210526315788\n",
      "24\n",
      "0.05485879084927604\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1411.955488637643\n",
      "testing ber:  0.10142543859649122\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  928.7783673078493\n",
      "testing ber:  0.13706140350877194\n",
      "25\n",
      "0.05590045384745648\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1368.7004134210047\n",
      "testing ber:  0.09703947368421052\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0009, dtype=torch.float64)\n",
      "percent loss:  1176.4726451054923\n",
      "testing ber:  0.14692982456140352\n",
      "26\n",
      "0.054176267533701784\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1386.075702637529\n",
      "testing ber:  0.09978070175438597\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1004.3598088458076\n",
      "testing ber:  0.14199561403508773\n",
      "27\n",
      "0.055226672678551775\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1399.9790347925752\n",
      "testing ber:  0.09868421052631579\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1104.091289292863\n",
      "testing ber:  0.14144736842105263\n",
      "28\n",
      "0.05199847885585846\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1410.3975273396916\n",
      "testing ber:  0.0981359649122807\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  991.2563399908466\n",
      "testing ber:  0.1387061403508772\n",
      "29\n",
      "0.053265786125384115\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1428.570333662988\n",
      "testing ber:  0.09703947368421052\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1225.1565503765155\n",
      "testing ber:  0.14089912280701755\n",
      "30\n",
      "0.056441009866985234\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1460.4314102531143\n",
      "testing ber:  0.09868421052631579\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  870.0662786148191\n",
      "testing ber:  0.14089912280701755\n",
      "31\n",
      "0.05572602913734761\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1435.1400142276605\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1230.5151767186533\n",
      "testing ber:  0.13486842105263158\n",
      "32\n",
      "0.053327990537311167\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1422.5449939018429\n",
      "testing ber:  0.09703947368421052\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1065.235220012922\n",
      "testing ber:  0.1299342105263158\n",
      "33\n",
      "0.055236843117374056\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1414.5706059479817\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1006.2892256332165\n",
      "testing ber:  0.14309210526315788\n",
      "34\n",
      "0.054721116405376725\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1425.4611554954774\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1013.6133405243437\n",
      "testing ber:  0.12554824561403508\n",
      "35\n",
      "0.05434975337157858\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1405.3573281193114\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1201.7514950636478\n",
      "testing ber:  0.14199561403508773\n",
      "36\n",
      "0.05445654992450108\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1438.721290435131\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1027.1206517323874\n",
      "testing ber:  0.13541666666666666\n",
      "37\n",
      "0.05464798849115663\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1423.7736887682738\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1061.3780685246577\n",
      "testing ber:  0.15515350877192982\n",
      "38\n",
      "0.05206684401615503\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1439.7835294016088\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1055.1718125666093\n",
      "testing ber:  0.14199561403508773\n",
      "39\n",
      "0.052387054246711605\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1445.8775788771559\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0009, dtype=torch.float64)\n",
      "percent loss:  1127.1595906926404\n",
      "testing ber:  0.14638157894736842\n",
      "40\n",
      "0.05312648732611473\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1463.0614256242707\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1038.66484974673\n",
      "testing ber:  0.15296052631578946\n",
      "41\n",
      "0.054132979957664265\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1456.0092539505306\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1091.1244016333628\n",
      "testing ber:  0.12609649122807018\n",
      "42\n",
      "0.05137706784769259\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1441.0066015339169\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1130.8717886683683\n",
      "testing ber:  0.1513157894736842\n",
      "43\n",
      "0.05342257956161778\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1485.8142660119115\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  876.219509486938\n",
      "testing ber:  0.13157894736842105\n",
      "44\n",
      "0.054138132876300434\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1437.0038771081831\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1146.4653816434402\n",
      "testing ber:  0.1474780701754386\n",
      "45\n",
      "0.05264987971911088\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1496.5006731104415\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  906.7220976458528\n",
      "testing ber:  0.13322368421052633\n",
      "46\n",
      "0.053503543396103886\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1457.2950038112235\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1186.9211705414175\n",
      "testing ber:  0.14418859649122806\n",
      "47\n",
      "0.05120474186309792\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1468.277825935615\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  899.1086929789049\n",
      "testing ber:  0.14418859649122806\n",
      "48\n",
      "0.05351018097172392\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1471.4034237737862\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1205.2216085584907\n",
      "testing ber:  0.13980263157894737\n",
      "49\n",
      "0.05184028785120934\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1475.1651004850196\n",
      "testing ber:  0.09594298245614036\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  991.6443944100064\n",
      "testing ber:  0.15021929824561403\n",
      "50\n",
      "0.05269151874520677\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1481.7073599400721\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1107.452022834556\n",
      "testing ber:  0.13651315789473684\n",
      "51\n",
      "0.051709693559306734\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1469.507204863266\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1029.0751135137864\n",
      "testing ber:  0.15734649122807018\n",
      "52\n",
      "0.05324974876055692\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1480.229455743762\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1096.5015509022412\n",
      "testing ber:  0.125\n",
      "53\n",
      "0.05181722727386241\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1466.7323372324906\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1143.6530595284282\n",
      "testing ber:  0.15460526315789475\n",
      "54\n",
      "0.052515419279324245\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1485.171239755013\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  929.7904455051792\n",
      "testing ber:  0.12609649122807018\n",
      "55\n",
      "0.05393675608718966\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1449.79177605409\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1115.2614456914625\n",
      "testing ber:  0.14912280701754385\n",
      "56\n",
      "0.05086728578750441\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1483.86241483398\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  866.311577531413\n",
      "testing ber:  0.1337719298245614\n",
      "57\n",
      "0.05140852961847757\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1453.3463722521442\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0009, dtype=torch.float64)\n",
      "percent loss:  1288.3387519273583\n",
      "testing ber:  0.14857456140350878\n",
      "58\n",
      "0.051502328653364106\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1509.9659220075284\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  841.1698614346159\n",
      "testing ber:  0.13048245614035087\n",
      "59\n",
      "0.05265912653363131\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1478.730736681857\n",
      "testing ber:  0.09265350877192982\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1276.4908920786713\n",
      "testing ber:  0.14089912280701755\n",
      "60\n",
      "0.050285185756597746\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1493.234045578275\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  984.3829643632204\n",
      "testing ber:  0.14089912280701755\n",
      "61\n",
      "0.05235856643659954\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1483.78425934862\n",
      "testing ber:  0.09265350877192982\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1074.9149584370837\n",
      "testing ber:  0.13596491228070176\n",
      "62\n",
      "0.05360041993689981\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1498.4317990801815\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1024.1371600074417\n",
      "testing ber:  0.1387061403508772\n",
      "63\n",
      "0.055430703538846465\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1501.203256581064\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  895.3106172856305\n",
      "testing ber:  0.12554824561403508\n",
      "64\n",
      "0.051145574583255866\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1492.6226939156866\n",
      "testing ber:  0.09320175438596491\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1244.0113662307774\n",
      "testing ber:  0.1387061403508772\n",
      "65\n",
      "0.05074476685493867\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1524.0006705925862\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  872.6470157475941\n",
      "testing ber:  0.12774122807017543\n",
      "66\n",
      "0.05117445613475556\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1505.120592421104\n",
      "testing ber:  0.09320175438596491\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1163.1936482391097\n",
      "testing ber:  0.13980263157894737\n",
      "67\n",
      "0.049736949020719276\n",
      "testing MSE:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0020, dtype=torch.float64)\n",
      "percent loss:  1507.9171433287356\n",
      "testing ber:  0.12554824561403508\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  892.2729250971121\n",
      "testing ber:  0.13541666666666666\n",
      "68\n",
      "0.049559384198027086\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1528.0325556181067\n",
      "testing ber:  0.09046052631578948\n",
      "testing MSE:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0009, dtype=torch.float64)\n",
      "percent loss:  1163.3171975102564\n",
      "testing ber:  0.13980263157894737\n",
      "69\n",
      "0.05428071466690682\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1516.9418907856088\n",
      "testing ber:  0.09265350877192982\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  821.9879329454583\n",
      "testing ber:  0.14144736842105263\n",
      "70\n",
      "0.05333522797383843\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1524.6376425525834\n",
      "testing ber:  0.09100877192982457\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  1034.0865393711224\n",
      "testing ber:  0.11951754385964912\n",
      "71\n",
      "0.04857802306836907\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1508.4824558462074\n",
      "testing ber:  0.09265350877192982\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1080.23747105802\n",
      "testing ber:  0.14638157894736842\n",
      "72\n",
      "0.05359998422655019\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1511.3427660474213\n",
      "testing ber:  0.09155701754385964\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  949.6724300258414\n",
      "testing ber:  0.12664473684210525\n",
      "73\n",
      "0.05401473622174656\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1529.4162333197912\n",
      "testing ber:  0.09868421052631579\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  912.3407044002633\n",
      "testing ber:  0.12445175438596491\n",
      "74\n",
      "0.05119968629739386\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1565.6852600381667\n",
      "testing ber:  0.09210526315789473\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1046.8156630984297\n",
      "testing ber:  0.14364035087719298\n",
      "75\n",
      "0.04888159550845306\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1541.4945460757\n",
      "testing ber:  0.08881578947368421\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  946.8753120203613\n",
      "testing ber:  0.12116228070175439\n",
      "76\n",
      "0.05093300031458444\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1506.248355539644\n",
      "testing ber:  0.09100877192982457\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0010, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1008.9610811216082\n",
      "testing ber:  0.14089912280701755\n",
      "77\n",
      "0.050771847297932875\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1558.2425475076227\n",
      "testing ber:  0.09978070175438597\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  874.9087240461878\n",
      "testing ber:  0.12171052631578948\n",
      "78\n",
      "0.05095628405267254\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1559.9682636463506\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  962.7123759016001\n",
      "testing ber:  0.12938596491228072\n",
      "79\n",
      "0.04910732079495458\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1518.9674777918513\n",
      "testing ber:  0.09155701754385964\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  974.1539630541489\n",
      "testing ber:  0.1206140350877193\n",
      "80\n",
      "0.048356623537442155\n",
      "testing MSE:  tensor(0.0031, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0044, dtype=torch.float64)\n",
      "percent loss:  1543.108994023749\n",
      "testing ber:  0.14528508771929824\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1043.9611634280307\n",
      "testing ber:  0.13541666666666666\n",
      "81\n",
      "0.05087588620471194\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1559.4989438218201\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  946.7112707048299\n",
      "testing ber:  0.12828947368421054\n",
      "82\n",
      "0.05063241821257992\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1518.610085375097\n",
      "testing ber:  0.09265350877192982\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  877.9118399172289\n",
      "testing ber:  0.11951754385964912\n",
      "83\n",
      "0.04918571343605823\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1537.6267596462294\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0010, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  1091.0249728895233\n",
      "testing ber:  0.13760964912280702\n",
      "84\n",
      "0.0500127308248998\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1522.306481746559\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0002, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  771.4472241733029\n",
      "testing ber:  0.11403508771929824\n",
      "85\n",
      "0.05208022363404644\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1514.347019141759\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0009, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  996.769877825137\n",
      "testing ber:  0.13103070175438597\n",
      "86\n",
      "0.05105649398520906\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1528.803231073546\n",
      "testing ber:  0.09539473684210527\n",
      "testing MSE:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  796.7456505964795\n",
      "testing ber:  0.11293859649122807\n",
      "87\n",
      "0.05045173505440037\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1512.8362415521742\n",
      "testing ber:  0.09320175438596491\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  1012.7122726313916\n",
      "testing ber:  0.12719298245614036\n",
      "88\n",
      "0.050187419208281854\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1505.9824095452327\n",
      "testing ber:  0.09649122807017543\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  859.0504739400704\n",
      "testing ber:  0.1299342105263158\n",
      "89\n",
      "0.050852016258509235\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1524.8051283731966\n",
      "testing ber:  0.09320175438596491\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  925.9209975035288\n",
      "testing ber:  0.11951754385964912\n",
      "90\n",
      "0.051113604607575754\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1494.5719229212561\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  947.5259190514471\n",
      "testing ber:  0.13157894736842105\n",
      "91\n",
      "0.05084988950414861\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1521.3230218350093\n",
      "testing ber:  0.09484649122807018\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0004, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0007, dtype=torch.float64)\n",
      "percent loss:  852.9742772223407\n",
      "testing ber:  0.11293859649122807\n",
      "92\n",
      "0.04879233958397774\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1490.2622090696107\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  976.0840647167474\n",
      "testing ber:  0.12280701754385964\n",
      "93\n",
      "0.04999933572129366\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1497.8985636194739\n",
      "testing ber:  0.09429824561403509\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0003, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  743.6019542629763\n",
      "testing ber:  0.10800438596491228\n",
      "94\n",
      "0.05187902721437685\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1508.4946897698294\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0008, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  990.2953208122427\n",
      "testing ber:  0.12335526315789473\n",
      "95\n",
      "0.0522753075062436\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1515.0022754549748\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0006, dtype=torch.float64)\n",
      "percent loss:  760.9472661195019\n",
      "testing ber:  0.12280701754385964\n",
      "96\n",
      "0.05100183906231789\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1546.1931990460557\n",
      "testing ber:  0.09155701754385964\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  954.219974649887\n",
      "testing ber:  0.13103070175438597\n",
      "97\n",
      "0.047819341830116636\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1517.5196357232248\n",
      "testing ber:  0.09375\n",
      "testing MSE:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  852.3322027738936\n",
      "testing ber:  0.12609649122807018\n",
      "98\n",
      "0.04919866414027328\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1506.0773148326307\n",
      "testing ber:  0.09320175438596491\n",
      "testing MSE:  tensor(0.0007, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0006, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0008, dtype=torch.float64)\n",
      "percent loss:  916.0111037147483\n",
      "testing ber:  0.11567982456140351\n",
      "99\n",
      "0.049133506445016\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1512.5140348721736\n",
      "testing ber:  0.09210526315789473\n",
      "testing MSE:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0005, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0005, dtype=torch.float64)\n",
      "percent loss:  765.41679111676\n",
      "testing ber:  0.1206140350877193\n"
     ]
    }
   ],
   "source": [
    "mutual_train(train_loader, test_loader, net_snn, net_dnn, net_lstm, nb_inputs, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bce4a5c2-38de-466c-ab45-ae78ecfc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(output, target):\n",
    "    #loss = (output - target) ** 2 / (target ** 2 + 1e-6)\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def train(trainloader, testloader, model, DNN_model, rc, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    params = list(model.parameters()) + list(DNN_model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    #loss_fn = ber_loss\n",
    "    loss_hist = []\n",
    "    DNN_model.train()\n",
    "    \n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        local_loss = []\n",
    "        for x_local, x1_local, x2_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            #output = model(x_local)\n",
    "            #output = output.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_local)\n",
    "            output = DNN_model(output, x1_local, x2_local)\n",
    "            loss_val = loss_fn(output, y_local) \n",
    "            loss_val.backward()\n",
    "            #print(\"AAAA: \", DNN_model.fc2.weight)\n",
    "            #print(\"BBBB: \", DNN_model.fc1.weight.grad)\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "            \n",
    "        \n",
    "        #if e % 1 == 30 and e != 0:\n",
    "        #    print(\"Training accuracy: %.3f\"%(compute_ber(trainloader, net, \"train\")))\n",
    "        #    print(\"Test accuracy: %.3f\"%(compute_ber(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(mean_loss)\n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        #test(testloader, model, DNN_model)\n",
    "        #test_train(trainloader, model, DNN_model)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f574380-3878-4cbd-9a38-19da46e5efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.16545830064631523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/3983635306.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_96/3983635306.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_96/3983635306.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_96/3983635306.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0110, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0098, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0123, dtype=torch.float64)\n",
      "percent loss:  2913.543207506088\n",
      "testing ber:  0.29660087719298245\n",
      "1\n",
      "0.09254795027540084\n",
      "testing MSE:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0036, dtype=torch.float64)\n",
      "percent loss:  1424.6953153762524\n",
      "testing ber:  0.21326754385964913\n",
      "2\n",
      "0.06021252561836166\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0013, dtype=torch.float64)\n",
      "percent loss:  1141.5854933795567\n",
      "testing ber:  0.09429824561403509\n",
      "3\n",
      "0.040663542562818275\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0012, dtype=torch.float64)\n",
      "percent loss:  1167.347360962157\n",
      "testing ber:  0.07182017543859649\n",
      "4\n",
      "0.03806374897744427\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0011, dtype=torch.float64)\n",
      "percent loss:  1203.2093589842525\n",
      "testing ber:  0.05646929824561404\n",
      "5\n",
      "0.03636001456687425\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0013, dtype=torch.float64)\n",
      "percent loss:  1333.2857078221139\n",
      "testing ber:  0.06414473684210527\n",
      "6\n",
      "0.036167724414708766\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1391.5979355886466\n",
      "testing ber:  0.09210526315789473\n",
      "7\n",
      "0.03717463707273945\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1556.1320559828434\n",
      "testing ber:  0.09484649122807018\n",
      "8\n",
      "0.03530595293070408\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1524.4923651325487\n",
      "testing ber:  0.13267543859649122\n",
      "9\n",
      "0.03552302248538174\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1547.1377815282972\n",
      "testing ber:  0.07675438596491228\n",
      "10\n",
      "0.03564054532808826\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1538.9546850180461\n",
      "testing ber:  0.1112938596491228\n",
      "11\n",
      "0.0379266112329478\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1496.6957340880845\n",
      "testing ber:  0.08607456140350878\n",
      "12\n",
      "0.03507729867433614\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1535.798816306475\n",
      "testing ber:  0.08333333333333333\n",
      "13\n",
      "0.03535062607694814\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1529.6695516626078\n",
      "testing ber:  0.09539473684210527\n",
      "14\n",
      "0.04084846997593946\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1434.3459560843346\n",
      "testing ber:  0.08278508771929824\n",
      "15\n",
      "0.0356034031930439\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1505.718018613524\n",
      "testing ber:  0.07456140350877193\n",
      "16\n",
      "0.035215479936054415\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1505.4724275181331\n",
      "testing ber:  0.07675438596491228\n",
      "17\n",
      "0.035423841604844054\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1480.6096801445979\n",
      "testing ber:  0.07401315789473684\n",
      "18\n",
      "0.035098676153636994\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1487.329629568094\n",
      "testing ber:  0.07730263157894737\n",
      "19\n",
      "0.03490397561975616\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1479.4261077155672\n",
      "testing ber:  0.0805921052631579\n",
      "20\n",
      "0.0348967604458015\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1500.6839402749079\n",
      "testing ber:  0.07839912280701754\n",
      "21\n",
      "0.03488232288509607\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1461.9329730100492\n",
      "testing ber:  0.07949561403508772\n",
      "22\n",
      "0.03495757176758761\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1464.3125379615874\n",
      "testing ber:  0.07839912280701754\n",
      "23\n",
      "0.03480873744379967\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1483.8184660725217\n",
      "testing ber:  0.08333333333333333\n",
      "24\n",
      "0.03477165285260119\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1477.249728925985\n",
      "testing ber:  0.0762061403508772\n",
      "25\n",
      "0.0348414527648624\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1467.6421948454467\n",
      "testing ber:  0.08333333333333333\n",
      "26\n",
      "0.034721106429524876\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1471.6610541737887\n",
      "testing ber:  0.07949561403508772\n",
      "27\n",
      "0.03526653333547267\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1452.91557301496\n",
      "testing ber:  0.07839912280701754\n",
      "28\n",
      "0.034693295195540215\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1488.6682690775879\n",
      "testing ber:  0.0800438596491228\n",
      "29\n",
      "0.03483801283576387\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1464.8494242441345\n",
      "testing ber:  0.0805921052631579\n",
      "30\n",
      "0.03479858335266088\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1461.3136908025933\n",
      "testing ber:  0.08607456140350878\n",
      "31\n",
      "0.03470845197505774\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1471.1585675964843\n",
      "testing ber:  0.08168859649122807\n",
      "32\n",
      "0.03488686341950868\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1481.8525599525099\n",
      "testing ber:  0.08114035087719298\n",
      "33\n",
      "0.034589758004121327\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1455.5938498470975\n",
      "testing ber:  0.08662280701754387\n",
      "34\n",
      "0.03555081015888681\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1485.6622133121157\n",
      "testing ber:  0.08223684210526316\n",
      "35\n",
      "0.034708299020186385\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1493.526890526913\n",
      "testing ber:  0.08223684210526316\n",
      "36\n",
      "0.03486915515299807\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1500.7637835466971\n",
      "testing ber:  0.08333333333333333\n",
      "37\n",
      "0.03480824257465119\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1456.1746258366773\n",
      "testing ber:  0.08223684210526316\n",
      "38\n",
      "0.034648657340477125\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1454.3779676321299\n",
      "testing ber:  0.08223684210526316\n",
      "39\n",
      "0.03466956228255592\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1481.654751682991\n",
      "testing ber:  0.08333333333333333\n",
      "40\n",
      "0.0345801697013543\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1442.1942600371954\n",
      "testing ber:  0.08278508771929824\n",
      "41\n",
      "0.034653318114578724\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1436.6532821127416\n",
      "testing ber:  0.08333333333333333\n",
      "42\n",
      "0.03466360564244554\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainloader, testloader, model, DNN_model, rc, lr, nb_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(local_loss)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_loss)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_loader, net_snn, net_dnn, rc, num_frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m input1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input1)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input2)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet_snn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m net_dnn(output, input1, input2)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m all_output\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, spike):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 37\u001b[0m         spike \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spike\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/block/base.py:1149\u001b[0m, in \u001b[0;36mAbstractRecurrent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     dendrite \u001b[38;5;241m=\u001b[39m z[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, time:time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1148\u001b[0m     feedback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_synapse(spike\u001b[38;5;241m.\u001b[39mreshape(dendrite\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m-> 1149\u001b[0m     spike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdendrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, time:time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m spike\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike_state \u001b[38;5;241m=\u001b[39m spike\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mreshape(z\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:433\u001b[0m, in \u001b[0;36mNeuron.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the full response of the neuron instance to an input.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    The input shape must match with the neuron shape. For the first time,\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    the neuron shape is determined from the input automatically.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     _, voltage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike(voltage)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:351\u001b[0m, in \u001b[0;36mNeuron.dynamics\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamp()\n\u001b[0;32m--> 351\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[43mleaky_integrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(current)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:93\u001b[0m, in \u001b[0;36mdynamics\u001b[0;34m(input, decay, state, w_scale, threshold, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m     state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_LIDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     output \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mdynamics(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcontiguous(), decay\u001b[38;5;241m.\u001b[39mcontiguous(), state\u001b[38;5;241m.\u001b[39mcontiguous(),\n\u001b[1;32m     97\u001b[0m         threshold, w_scale\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:129\u001b[0m, in \u001b[0;36m_LIDynamics.forward\u001b[0;34m(ctx, input, decay, state, threshold, w_scale)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_li_dynamics_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _LIDynamics\u001b[38;5;241m.\u001b[39mDEBUG \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         _output, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mfwd(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale\n\u001b[1;32m    137\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:215\u001b[0m, in \u001b[0;36m_li_dynamics_fwd\u001b[0;34m(input, decay, state, threshold, w_scale, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m output_old \u001b[38;5;241m=\u001b[39m (state \u001b[38;5;241m*\u001b[39m w_scale)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(dtype)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 215\u001b[0m decay_int \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m threshold \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m w_scale\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/_tensor.py:28\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, net_snn, net_dnn, rc, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac761138-0e7d-42b0-a0ed-c75ab87036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219/3403701246.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_219/3403701246.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_219/3403701246.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_219/3403701246.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE RC:  tensor(0.0051, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0036, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "RC_train_time = np.load(\"gt_train_pred.npy\")\n",
    "print(\"train MSE: \", torch.nn.MSELoss()(torch.tensor(RC_train_time), torch.tensor(train_label)))\n",
    "def test_train_both(train_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in train_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    print(\"train MSE RC: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(RC_train_time)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(train_label)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(train_label), torch.tensor(RC_train_time)))\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_train_both(train_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808d7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_snn.export_hdf5('./net_snn.net')\n",
    "torch.save(net_dnn.state_dict(), './net_dnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "898cb37e-9af7-45f8-a3e2-8ddbd0db0dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/229205384.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/229205384.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/229205384.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/229205384.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7521, 2]) torch.Size([7521, 2])\n",
      "all_loss:  tensor(0.0024)\n",
      "no first 330 loss:  tensor(0.0014)\n"
     ]
    }
   ],
   "source": [
    "temp_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test_MSE(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "    \n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "    \n",
    "    all_output = torch.tensor(np.concatenate(all_output, axis=0)).detach()\n",
    "    labels = torch.tensor(np.concatenate(labels, axis=0)).detach()\n",
    "    print(all_output.shape, labels.shape)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    print(\"all_loss: \", loss_fn(all_output, labels))\n",
    "    print(\"no first 330 loss: \", loss_fn(all_output[330:, :], labels[330:, :]))\n",
    "\n",
    "test_MSE(temp_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7acff8c-50b2-4bd2-93f8-b3106dddedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/3202473027.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/3202473027.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/3202473027.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/3202473027.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18902153558052434\n"
     ]
    }
   ],
   "source": [
    "all_output = []\n",
    "inputs = []\n",
    "labels = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    ber = rc.my_test(all_output)\n",
    "    print(ber)\n",
    "    \n",
    "test(test_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ee219a-952a-4395-b2a9-db85d18f17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        ...,\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "A1 = 8 * torch.ones((128, 8))\n",
    "A2 = torch.ones((128, 1))\n",
    "print(A1 + A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eebf40-ab07-4dda-9afb-3caa814cefa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
