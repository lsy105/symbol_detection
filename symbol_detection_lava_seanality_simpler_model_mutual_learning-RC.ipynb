{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138b6027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cpu\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "#import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from dataset import Dataset, SpikingDataset, RegSpikingDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from Loss import KDLoss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "random.seed(1338)\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pyESN import ESN\n",
    "from scipy import interpolate\n",
    "from gen_data import *\n",
    "from tanh import tanh\n",
    "\n",
    "from Loss import ber_loss\n",
    "\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import slayer from lava-dl\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "import IPython.display as display\n",
    "from matplotlib import animation\n",
    "\n",
    "generating_data = False\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "torch.__version__\n",
    "# The coarse network structure is dicated by the Fashion MNIST dataset. \n",
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "    #device = torch.device(\"cuda\")     \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)\n",
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "time_step = 1e-3\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663fb05d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gt_test_input_1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m rc \u001b[38;5;241m=\u001b[39m RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n\u001b[1;32m     48\u001b[0m         N_reservoir\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     49\u001b[0m         spectral_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m         sock\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# usock\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         addr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# addr\u001b[39;00m\n\u001b[1;32m     63\u001b[0m train_input, train_label, test_input, test_label \u001b[38;5;241m=\u001b[39m rc\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m---> 64\u001b[0m RC_test_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgt_test_input_1.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m RC_train_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_train_input_1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m RC_train_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_train_label_1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gt_test_input_1.npy'"
     ]
    }
   ],
   "source": [
    "silent = True\n",
    "method = 'RLS'  # RLS; INV; INV+RLS\n",
    "# N_total_frame = 17\n",
    "N_total_frame = 94\n",
    "N_sync_frame = 4\n",
    "# SNR_list = np.arange(1,20,2)\n",
    "SNR_list = [55]\n",
    "\n",
    "# Dataset selection\n",
    "folder_name = 'data/S2/'  # LOS_Near:S2, LOS_Far:S3, NLOS:S1\n",
    "output_folder = 'data_outputs/S1'\n",
    "\n",
    "if folder_name == 'data/S1/':  # NLOS\n",
    "    delay = 0\n",
    "    packet_num = 21\n",
    "elif folder_name == 'data/S2/':  # LOS_Near\n",
    "    delay = 1\n",
    "    packet_num = 27 # correct\n",
    "elif folder_name == 'data/S3/':  # LOS_Far\n",
    "    delay = 1\n",
    "    packet_num = 22 # 23\n",
    "else:\n",
    "    print(\"Undefined Dataset\")\n",
    "    exit(1)\n",
    "    \n",
    "window_size = 2\n",
    "N_reservoir = 16\n",
    "debug = False\n",
    "\n",
    "ber_record = []\n",
    "dfe_ber_record = []\n",
    "LS_ber_record = []\n",
    "comb_ber_record = []\n",
    "sta_ber_record = []\n",
    "tanh_lut = tanh(\n",
    "    input_bit=8,\n",
    "    dx_bit=8,\n",
    "    slope_fmt=(10, 10),\n",
    "    intercept_fmt=(19, 19),\n",
    "    max=8,\n",
    "    better_lut=True,\n",
    "    verbose=False,\n",
    "    plot=False)\n",
    "\n",
    "SNR = SNR_list[0]\n",
    "i = 16\n",
    "rc = RC(silent, method, N_total_frame, N_sync_frame, SNR, delay, window_size, i,\n",
    "        N_reservoir=16,\n",
    "        spectral_radius=0.2,\n",
    "        sparsity=0.4,\n",
    "        noise=1e-6,\n",
    "        lut_activation=False,  # True,\n",
    "        tanh_lut=tanh_lut,\n",
    "        input_scale=25,  #40, #50, # 25,\n",
    "        reservoir_input_scale = 8,  #4,  #5,\n",
    "        show_wout=False,\n",
    "        output_folder= output_folder,\n",
    "        debug=debug,\n",
    "        use_fpga= None,\n",
    "        sock= None,  # usock\n",
    "        addr = None) # addr\n",
    "\n",
    "train_input, train_label, test_input, test_label = rc.run()\n",
    "RC_test_input = np.load('gt_test_input_1.npy')\n",
    "RC_train_input = np.load('gt_train_input_1.npy')\n",
    "RC_train_label = np.load('gt_train_label_1.npy')\n",
    "\n",
    "print(RC_test_input.shape, test_input.shape)\n",
    "print(\"test_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_test_input), torch.tensor(test_input)))\n",
    "\n",
    "print(\"train_input_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_input), torch.tensor(train_input)))\n",
    "\n",
    "print(\"train_label_diff: \", torch.nn.MSELoss()(torch.tensor(RC_train_label), torch.tensor(train_label)))\n",
    "\n",
    "train_mean = np.mean(train_input)\n",
    "train_std = np.std(train_input)\n",
    "\n",
    "train_input = (train_input - train_mean) / train_std\n",
    "test_input = (test_input - train_mean) / train_std\n",
    "train_label = 1.0 * train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input.shape)\n",
    "print(test_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7395dfe-dc16-458e-989e-b39bfcc397e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def pre_processing(train_input, train_label):\n",
    "    idx_p = 10\n",
    "    begin = 0 # N_total_frame * N_sync_frame\n",
    "    \n",
    "    # label index for data\n",
    "    train_input_df = pd.DataFrame(train_input, columns = ['1','2', '3', '4'])\n",
    "    #train_input_df['L1_idx'] = train_input_df.index % idx_p\n",
    "\n",
    "    # label index for label\n",
    "    train_label_df = pd.DataFrame(train_label, columns = ['L1','L2'])\n",
    "    train_label_df['L1_idx'] = train_label_df.index % idx_p\n",
    "    \n",
    "    # split training and testing data\n",
    "    test_input_df, test_label_df = train_input_df.iloc[75* 80 + 1:, :], train_label_df.iloc[75* 80 + 1:, :]\n",
    "    train_input_df, train_label_df = train_input_df.iloc[:75* 80 + 1, :], train_label_df.iloc[:75* 80 + 1, :]\n",
    "\n",
    "    # group by \n",
    "    #mapping = train_label_df.loc[begin:, :].groupby(by='L1_idx').mean().reset_index().loc[:, ['L1', 'L2', 'L1_idx']] \n",
    "    \n",
    "    #train_input_df = pd.merge(train_input_df, mapping, how='left', on='L1_idx')\n",
    "\n",
    "    #train_input_df = pd.get_dummies(train_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    train_input_df = train_input_df.loc[begin:, :]\n",
    "\n",
    "\n",
    "    print(train_input_df.head())\n",
    "    \n",
    "    # testing data\n",
    "    # group by\n",
    "    #test_input_df = test_input_df.merge(mapping, how = 'left', on='L1_idx')\n",
    "\n",
    "    #test_input_df = pd.get_dummies(test_input_df, prefix=['L'], columns=['L1_idx'])\n",
    "\n",
    "    print(test_input_df.head())\n",
    "\n",
    "    train_input = train_input_df.to_numpy()\n",
    "    test_input = test_input_df.to_numpy()\n",
    "    \n",
    "    train_label = train_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    test_label = test_label_df.drop(['L1_idx'], axis=1).to_numpy()\n",
    "    \n",
    "    print(train_input.shape)\n",
    "    print(test_input.shape)\n",
    "    \n",
    "    \n",
    "    return train_input, train_label, test_input, test_label\n",
    "\n",
    "train_input, train_label, test_input, test_label = pre_processing(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acdc9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7521\n",
      "(24, 100)\n",
      "(1,)\n",
      "(24,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "nb_inputs  = 6\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "from dataset import Dataset, RegTorchSeasonalitySpikingDataset, RegSpikingDataset, RegTorchSpikingDataset, RegTorchSeasonalityLinearSpikingDataset\n",
    "train_data = RegTorchSeasonalityLinearSpikingDataset(train_input, train_label, nb_inputs, nb_steps)\n",
    "test_data = RegTorchSeasonalityLinearSpikingDataset(test_input, test_label, nb_inputs, nb_steps)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244a41ed-51c7-413b-8ae8-4585d6fc485b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate fixed dataset\n",
    "if generating_data:\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    for i in range(len(train_data)):\n",
    "        X, X1, X_p, y = train_data[i]\n",
    "        training_data.append([X, X1, X_p, y])\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        X, X1, X_p, y = test_data[i]\n",
    "        testing_data.append([X, X1, X_p, y])\n",
    "\n",
    "    np.save('training_data.npy', training_data)\n",
    "    np.save('testing_data.npy', testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3605ae03-9e11-4473-8bcc-2e72f2d6a350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom dataset import AMySpikingDataset\\n\\ntraining_data = np.load('training_data.npy', allow_pickle=True)\\ntesting_data = np.load('testing_data.npy', allow_pickle=True)\\n\\ntrain_data = AMySpikingDataset(training_data)\\ntest_data = AMySpikingDataset(testing_data)\\ntrain_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\\ntest_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\\nprint(len(train_data))\\nprint(train_data[0][0].shape)\\nprint(train_data[0][1].shape)\\nprint(train_data[0][2].shape)\\nprint(train_data[0][3].shape)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from dataset import AMySpikingDataset\n",
    "\n",
    "training_data = np.load('training_data.npy', allow_pickle=True)\n",
    "testing_data = np.load('testing_data.npy', allow_pickle=True)\n",
    "\n",
    "train_data = AMySpikingDataset(training_data)\n",
    "test_data = AMySpikingDataset(testing_data)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print(len(train_data))\n",
    "print(train_data[0][0].shape)\n",
    "print(train_data[0][1].shape)\n",
    "print(train_data[0][2].shape)\n",
    "print(train_data[0][3].shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf4c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "       # neuron_params = {\n",
    "       #         'threshold'     : 0.1,\n",
    "       #         'current_decay' : 1,\n",
    "       #         'voltage_decay' : 0.1,\n",
    "       #         'requires_grad' : True,     \n",
    "       #     }\n",
    "        #neuron_params_drop = {**neuron_params, 'dropout' : slayer.neuron.Dropout(p=0.05),}\n",
    "        neuron_params = {\n",
    "                'threshold'     : 2.0,\n",
    "                'current_decay' : 0.25,\n",
    "                'voltage_decay' : 0.03,\n",
    "                'tau_grad'      : 0.03,\n",
    "                'scale_grad'    : 3,\n",
    "                'requires_grad' : True,   \n",
    "            \n",
    "            }\n",
    "        \n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([\n",
    "                #slayer.block.cuba.Input(neuron_params),\n",
    "                #slayer.block.cuba.Recurrent(neuron_params, input_size, 8, weight_norm=True, delay=True),\n",
    "                slayer.block.cuba.Dense(neuron_params, input_size, 8, weight_norm=True, delay=True, weight_scale=1.0),\n",
    "                slayer.block.cuba.Dense(neuron_params, 8, 1, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 8, 1, weight_norm=True, delay=True),\n",
    "                #slayer.block.cuba.Dense(neuron_params, 128, output_size, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, input_size, 64, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 64, 128, weight_scale=2, weight_norm=True),\n",
    "                #slayer.block.sigma_delta.Dense(sdnn_dense_params, 128, output_size, weight_scale=2, weight_norm=True)\n",
    "                #slayer.block.cuba.Recurrent(cuba_params, 100, 50),\n",
    "                #slayer.block.cuba.KWTA(cuba_params, 50, 50, num_winners=5)\n",
    "            ])\n",
    "    \n",
    "    def forward(self, spike):\n",
    "        for block in self.blocks:\n",
    "            spike = block(spike)\n",
    "        return spike\n",
    "\n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "\n",
    "class DNNNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2)\n",
    "        #self.fc2 = nn.Linear(16, 2)\n",
    "        #self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self,x, x1, x2):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = torch.cat((x, x2), axis=1)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.act(x)\n",
    "        #x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1084390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DFRSystem import *\n",
    "\n",
    "net_snn = Network(nb_inputs * 4, 2).to(device)\n",
    "net_dnn = DNNNetwork(1 * nb_steps + nb_inputs * 4 + 0 + 0 * nb_inputs, 2).to(device)\n",
    "net_rc = TOriFloatDFRSystem(n_hidden=16, n_fc=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8441bd-8c48-4451-a52d-88763313aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, net_snn, net_dnn, rc, num_frame = 19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        \n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    #print(\"testing MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    #print(\"testing MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    #print(\"testing MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    #print(\"percent loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing ber: \", rc.my_new_test(predict_time, target_time))\n",
    "\n",
    "\n",
    "def test_teacher(test_loader, model, rc, nb_inputs, num_frame=19):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "        \n",
    "        input2 = input2.view(input2.shape[0], nb_inputs, 4)\n",
    "        prev_out = 0.1 * torch.zeros(input2.size(0), model.n_hidden).to(device)\n",
    "        output = model(input2, prev_out)[0].cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        \n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "   \n",
    "    #print(\"testing teacher MSE: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(labels)))\n",
    "    #print(\"testing teacher MSE 0: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 0]), torch.tensor(labels[:, 0])))\n",
    "    #print(\"testing teacher MSE 1: \", torch.nn.MSELoss()(torch.tensor(all_output[:, 1]), torch.tensor(labels[:, 1])))\n",
    "    #print(all_output.shape, labels.shape)\n",
    "    #print(\"percent teacher loss: \", np.mean(np.abs(all_output - labels) / (np.abs(labels) + 1e-6)))\n",
    "    predict_time = rc.time_to_freq(all_output, num_frame, remove_delay=False)\n",
    "    target_time = rc.time_to_freq(labels, num_frame, remove_delay=False)\n",
    "    print(\"testing teacher ber: \", rc.my_new_test(predict_time, target_time))\n",
    "    return rc.my_new_test(predict_time, target_time)\n",
    "\n",
    "#test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "#test_teacher(test_loader, net_rc, rc, nb_inputs, num_frame=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79d3c6a-e9de-4838-b114-9c9c95972ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn(trainloader, testloader, net, rc, nb_inputs, lr=2e-3, nb_epochs=10):\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9,0.999), weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    loss_hist = []\n",
    "    best_ber = 10000000000.0\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        loss_hist = []\n",
    "        for x1_local, x2_local, x3_local, y_local in trainloader:\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            x3_local = x3_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # lstm model\n",
    "            x3_local = x3_local.view(x3_local.shape[0], nb_inputs, 4)\n",
    "            prev_out = torch.zeros(x3_local.size(0), net.n_hidden).to(device)\n",
    "            output = net(x3_local, prev_out)[0]\n",
    "            \n",
    "            loss = loss_fn(output, y_local)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "        print(np.mean(loss_hist))\n",
    "        \n",
    "        ber = test_teacher(test_loader, net, rc, nb_inputs, num_frame=19) \n",
    "        if ber < best_ber:\n",
    "            best_ber = ber\n",
    "            torch.save(net.state_dict(), './teacher.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3c9680-0bfd-4b4a-a685-c2ae4a85318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dnn(train_loader, test_loader, net_rc, rc, nb_inputs, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5bfc998-8021-46a1-ab16-d42e774c28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_loss(teacher_output, student_output, alpha, target, mode=True):\n",
    "    # student loss 1\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    \n",
    "    #compare \n",
    "    loss_t = loss_fn(teacher_output, target)\n",
    "    loss_s = loss_fn(student_output, target)\n",
    "    \n",
    "    loss1 = loss_fn(student_output, target)\n",
    "    loss2 = loss_fn(student_output, teacher_output)\n",
    "    if mode:\n",
    "        if loss_t >= loss_s:\n",
    "            return loss1\n",
    "        else:\n",
    "            return loss1 + alpha * loss2\n",
    "    else:\n",
    "        return (1 - alpha) * loss1 + alpha * loss2\n",
    "    \n",
    "def KD_train(trainloader, testloader, net_snn, net_dnn, net_teacher, rc, teacher_path, nb_inputs, lr=2e-3, nb_epochs=10):\n",
    "    net_teacher.load_state_dict(torch.load(teacher_path))\n",
    "    net_teacher.eval()\n",
    "    test_teacher(testloader, net_teacher, rc, nb_inputs, num_frame=19)\n",
    "    \n",
    "    params = list(net_snn.parameters()) + list(net_dnn.parameters())\n",
    "    optimizer_student = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    scheduler_student = torch.optim.lr_scheduler.StepLR(optimizer_student, step_size=200, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    loss_hist = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        loss_hist = []\n",
    "        for x1_local, x2_local, x3_local, y_local in trainloader:\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            x3_local = x3_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            optimizer_student.zero_grad()\n",
    "            \n",
    "            # snn model \n",
    "            output = net_snn(x1_local)\n",
    "            output = net_dnn(output, x2_local, x3_local)\n",
    "            \n",
    "            # lstm model\n",
    "            x3_local = x3_local.view(x3_local.shape[0], nb_inputs, 4)\n",
    "            prev_out = torch.zeros(x3_local.size(0), net_teacher.n_hidden).to(device)\n",
    "           # teacher_output, _ = net_teacher(x3_local, prev_out)\n",
    "            \n",
    "            #student_loss = mutual_loss(teacher_output.detach(), output, alpha=0.0, target=y_local, mode=True)\n",
    "            student_loss = loss_fn(output, y_local)\n",
    "            student_loss.backward()\n",
    "\n",
    "            optimizer_student.step()\n",
    "        \n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        #test_teacher(test_loader, net_teacher, rc, nb_inputs, num_frame=19)   \n",
    "\n",
    "def mutual_train(trainloader, testloader, net_snn, net_dnn, net_teacher, rc, nb_inputs, lr=2e-3, nb_epochs=10):\n",
    "    params = list(net_snn.parameters()) + list(net_dnn.parameters())\n",
    "    optimizer_student = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    optimizer_teacher = torch.optim.Adam(net_teacher.parameters(), lr=lr, betas=(0.9,0.999), weight_decay=1e-4)\n",
    "    scheduler_student = torch.optim.lr_scheduler.StepLR(optimizer_student, step_size=100, gamma=0.1)\n",
    "    scheduler_teacher = torch.optim.lr_scheduler.StepLR(optimizer_teacher, step_size=100, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.SmoothL1Loss()\n",
    "    loss_hist = []\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        loss_hist = []\n",
    "        for x1_local, x2_local, x3_local, y_local in trainloader:\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            x3_local = x3_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            optimizer_student.zero_grad()\n",
    "            optimizer_teacher.zero_grad()\n",
    "            \n",
    "            # snn model \n",
    "            output = net_snn(x1_local)\n",
    "            output = net_dnn(output, x2_local, x3_local)\n",
    "            \n",
    "            # lstm model\n",
    "            x3_local = x3_local.view(x3_local.shape[0], nb_inputs, 4)\n",
    "            prev_out = torch.zeros(x3_local.size(0), net_teacher.n_hidden).to(device)\n",
    "            teacher_output, _ = net_teacher(x3_local, prev_out)\n",
    "            \n",
    "            student_loss = mutual_loss(teacher_output.detach(), output, alpha=0.05, target=y_local, mode=True)\n",
    "            teacher_loss = mutual_loss(output.detach(), teacher_output, alpha=0.01, target=y_local, mode=False)\n",
    "            student_loss.backward()\n",
    "            teacher_loss.backward()\n",
    "            optimizer_student.step()\n",
    "            optimizer_teacher.step()\n",
    "            loss_hist.append(student_loss.item() + teacher_loss.item())\n",
    "        print(np.mean(loss_hist))\n",
    "        \n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        test_teacher(test_loader, net_teacher, rc, nb_inputs, num_frame=19)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e8c31f8-96da-43da-a25b-3a1a2b97677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649/3724917593.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_649/3724917593.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_649/3724917593.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_649/3724917593.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing teacher ber:  0.8103070175438597\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649/3724917593.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_649/3724917593.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_649/3724917593.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_649/3724917593.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing ber:  0.4413377192982456\n",
      "1\n",
      "testing ber:  0.34868421052631576\n",
      "2\n",
      "testing ber:  0.2982456140350877\n",
      "3\n",
      "testing ber:  0.27028508771929827\n",
      "4\n",
      "testing ber:  0.22697368421052633\n",
      "5\n",
      "testing ber:  0.17269736842105263\n",
      "6\n",
      "testing ber:  0.1650219298245614\n",
      "7\n",
      "testing ber:  0.14692982456140352\n",
      "8\n",
      "testing ber:  0.13980263157894737\n",
      "9\n",
      "testing ber:  0.1299342105263158\n",
      "10\n",
      "testing ber:  0.11458333333333333\n",
      "11\n",
      "testing ber:  0.10526315789473684\n",
      "12\n",
      "testing ber:  0.09868421052631579\n",
      "13\n",
      "testing ber:  0.10197368421052631\n",
      "14\n",
      "testing ber:  0.09978070175438597\n",
      "15\n",
      "testing ber:  0.09923245614035088\n",
      "16\n",
      "testing ber:  0.09429824561403509\n",
      "17\n",
      "testing ber:  0.09703947368421052\n",
      "18\n",
      "testing ber:  0.0981359649122807\n",
      "19\n",
      "testing ber:  0.09594298245614036\n",
      "20\n",
      "testing ber:  0.10032894736842106\n",
      "21\n",
      "testing ber:  0.10471491228070176\n",
      "22\n",
      "testing ber:  0.10032894736842106\n",
      "23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mKD_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_rc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./teacher.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36mKD_train\u001b[0;34m(trainloader, testloader, net_snn, net_dnn, net_teacher, rc, teacher_path, nb_inputs, lr, nb_epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     34\u001b[0m loss_hist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x1_local, x2_local, x3_local, y_local \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[1;32m     36\u001b[0m     x1_local \u001b[38;5;241m=\u001b[39m x1_local\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m     x2_local \u001b[38;5;241m=\u001b[39m x2_local\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Research/RC_wifi/dataset.py:207\u001b[0m, in \u001b[0;36mRegTorchSeasonalityLinearSpikingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    205\u001b[0m temp_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_data[i][:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m    206\u001b[0m temp_tensor \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m X1[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 207\u001b[0m temp_result \u001b[38;5;241m=\u001b[39m \u001b[43mbernoulli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(temp_result\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    209\u001b[0m X_p\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_data[i][:])\n",
      "File \u001b[0;32m~/Research/RC_wifi/encoder.py:42\u001b[0m, in \u001b[0;36mbernoulli\u001b[0;34m(datum, time, dt, device, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_prob \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum firing probability must be in range [0, 1]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (datum \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs must be non-negative\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m shape, size \u001b[38;5;241m=\u001b[39m \u001b[43mdatum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, datum\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m     43\u001b[0m datum \u001b[38;5;241m=\u001b[39m datum\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "KD_train(train_loader, test_loader, net_snn, net_dnn, net_rc, rc, './teacher.pt', nb_inputs, lr=1e-3, nb_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac16670-6fb3-40df-84d8-05708ff0350a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mutual_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m net_dnn \u001b[38;5;241m=\u001b[39m DNNNetwork(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m nb_inputs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m*\u001b[39m nb_inputs, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m net_rc \u001b[38;5;241m=\u001b[39m TOriFloatDFRSystem(n_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, n_fc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmutual_train\u001b[49m(train_loader, test_loader, net_snn, net_dnn, net_rc, rc, nb_inputs, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, nb_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mutual_train' is not defined"
     ]
    }
   ],
   "source": [
    "net_snn = Network(nb_inputs * 4, 2).to(device)\n",
    "net_dnn = DNNNetwork(1 * 100 + nb_inputs * 4 + 0 + 0 * nb_inputs, 2).to(device)\n",
    "net_rc = TOriFloatDFRSystem(n_hidden=16, n_fc=64)\n",
    "\n",
    "mutual_train(train_loader, test_loader, net_snn, net_dnn, net_rc, rc, nb_inputs, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bce4a5c2-38de-466c-ab45-ae78ecfc5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(output, target):\n",
    "    #loss = (output - target) ** 2 / (target ** 2 + 1e-6)\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def train(trainloader, testloader, model, DNN_model, rc, lr=2e-3, nb_epochs=10):\n",
    "    #params = [w1,w2]\n",
    "    params = list(model.parameters()) + list(DNN_model.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    #loss_fn = slayer.loss.SpikeTime(time_constant=2, filter_order=2, reduction='mean').to(device)\n",
    "    #loss_fn = torch.nn.MSELoss()\n",
    "    loss_fn = torch.nn.L1Loss()\n",
    "    #loss_fn = ber_loss\n",
    "    loss_hist = []\n",
    "    DNN_model.train()\n",
    "    \n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        print(e)\n",
    "        local_loss = []\n",
    "        for x_local, x1_local, x2_local, y_local in trainloader:\n",
    "            x_local = x_local.float().to(device)\n",
    "            x1_local = x1_local.float().to(device)\n",
    "            x2_local = x2_local.float().to(device)\n",
    "            y_local = y_local.float().to(device)\n",
    "    \n",
    "            #output = model(x_local)\n",
    "            #output = output.flatten(start_dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_local)\n",
    "            output = DNN_model(output, x1_local, x2_local)\n",
    "            loss_val = loss_fn(output, y_local) \n",
    "            loss_val.backward()\n",
    "            #print(\"AAAA: \", DNN_model.fc2.weight)\n",
    "            #print(\"BBBB: \", DNN_model.fc1.weight.grad)\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "            \n",
    "        \n",
    "        #if e % 1 == 30 and e != 0:\n",
    "        #    print(\"Training accuracy: %.3f\"%(compute_ber(trainloader, net, \"train\")))\n",
    "        #    print(\"Test accuracy: %.3f\"%(compute_ber(testloader, net, name)))\n",
    "        scheduler.step()\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(mean_loss)\n",
    "        test(test_loader, net_snn, net_dnn, rc, num_frame=19)\n",
    "        #print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        #test(testloader, model, DNN_model)\n",
    "        #test_train(trainloader, model, DNN_model)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f574380-3878-4cbd-9a38-19da46e5efdf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.16545830064631523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/3983635306.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_96/3983635306.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_96/3983635306.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_96/3983635306.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing MSE:  tensor(0.0110, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0098, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0123, dtype=torch.float64)\n",
      "percent loss:  2913.543207506088\n",
      "testing ber:  0.29660087719298245\n",
      "1\n",
      "0.09254795027540084\n",
      "testing MSE:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0037, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0036, dtype=torch.float64)\n",
      "percent loss:  1424.6953153762524\n",
      "testing ber:  0.21326754385964913\n",
      "2\n",
      "0.06021252561836166\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0013, dtype=torch.float64)\n",
      "percent loss:  1141.5854933795567\n",
      "testing ber:  0.09429824561403509\n",
      "3\n",
      "0.040663542562818275\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0012, dtype=torch.float64)\n",
      "percent loss:  1167.347360962157\n",
      "testing ber:  0.07182017543859649\n",
      "4\n",
      "0.03806374897744427\n",
      "testing MSE:  tensor(0.0012, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0011, dtype=torch.float64)\n",
      "percent loss:  1203.2093589842525\n",
      "testing ber:  0.05646929824561404\n",
      "5\n",
      "0.03636001456687425\n",
      "testing MSE:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0013, dtype=torch.float64)\n",
      "percent loss:  1333.2857078221139\n",
      "testing ber:  0.06414473684210527\n",
      "6\n",
      "0.036167724414708766\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1391.5979355886466\n",
      "testing ber:  0.09210526315789473\n",
      "7\n",
      "0.03717463707273945\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1556.1320559828434\n",
      "testing ber:  0.09484649122807018\n",
      "8\n",
      "0.03530595293070408\n",
      "testing MSE:  tensor(0.0019, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0020, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1524.4923651325487\n",
      "testing ber:  0.13267543859649122\n",
      "9\n",
      "0.03552302248538174\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1547.1377815282972\n",
      "testing ber:  0.07675438596491228\n",
      "10\n",
      "0.03564054532808826\n",
      "testing MSE:  tensor(0.0018, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0017, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0018, dtype=torch.float64)\n",
      "percent loss:  1538.9546850180461\n",
      "testing ber:  0.1112938596491228\n",
      "11\n",
      "0.0379266112329478\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1496.6957340880845\n",
      "testing ber:  0.08607456140350878\n",
      "12\n",
      "0.03507729867433614\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0017, dtype=torch.float64)\n",
      "percent loss:  1535.798816306475\n",
      "testing ber:  0.08333333333333333\n",
      "13\n",
      "0.03535062607694814\n",
      "testing MSE:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0016, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1529.6695516626078\n",
      "testing ber:  0.09539473684210527\n",
      "14\n",
      "0.04084846997593946\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1434.3459560843346\n",
      "testing ber:  0.08278508771929824\n",
      "15\n",
      "0.0356034031930439\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1505.718018613524\n",
      "testing ber:  0.07456140350877193\n",
      "16\n",
      "0.035215479936054415\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1505.4724275181331\n",
      "testing ber:  0.07675438596491228\n",
      "17\n",
      "0.035423841604844054\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1480.6096801445979\n",
      "testing ber:  0.07401315789473684\n",
      "18\n",
      "0.035098676153636994\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1487.329629568094\n",
      "testing ber:  0.07730263157894737\n",
      "19\n",
      "0.03490397561975616\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1479.4261077155672\n",
      "testing ber:  0.0805921052631579\n",
      "20\n",
      "0.0348967604458015\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1500.6839402749079\n",
      "testing ber:  0.07839912280701754\n",
      "21\n",
      "0.03488232288509607\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1461.9329730100492\n",
      "testing ber:  0.07949561403508772\n",
      "22\n",
      "0.03495757176758761\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1464.3125379615874\n",
      "testing ber:  0.07839912280701754\n",
      "23\n",
      "0.03480873744379967\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1483.8184660725217\n",
      "testing ber:  0.08333333333333333\n",
      "24\n",
      "0.03477165285260119\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1477.249728925985\n",
      "testing ber:  0.0762061403508772\n",
      "25\n",
      "0.0348414527648624\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1467.6421948454467\n",
      "testing ber:  0.08333333333333333\n",
      "26\n",
      "0.034721106429524876\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1471.6610541737887\n",
      "testing ber:  0.07949561403508772\n",
      "27\n",
      "0.03526653333547267\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1452.91557301496\n",
      "testing ber:  0.07839912280701754\n",
      "28\n",
      "0.034693295195540215\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1488.6682690775879\n",
      "testing ber:  0.0800438596491228\n",
      "29\n",
      "0.03483801283576387\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1464.8494242441345\n",
      "testing ber:  0.0805921052631579\n",
      "30\n",
      "0.03479858335266088\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1461.3136908025933\n",
      "testing ber:  0.08607456140350878\n",
      "31\n",
      "0.03470845197505774\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1471.1585675964843\n",
      "testing ber:  0.08168859649122807\n",
      "32\n",
      "0.03488686341950868\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1481.8525599525099\n",
      "testing ber:  0.08114035087719298\n",
      "33\n",
      "0.034589758004121327\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1455.5938498470975\n",
      "testing ber:  0.08662280701754387\n",
      "34\n",
      "0.03555081015888681\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1485.6622133121157\n",
      "testing ber:  0.08223684210526316\n",
      "35\n",
      "0.034708299020186385\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0016, dtype=torch.float64)\n",
      "percent loss:  1493.526890526913\n",
      "testing ber:  0.08223684210526316\n",
      "36\n",
      "0.03486915515299807\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1500.7637835466971\n",
      "testing ber:  0.08333333333333333\n",
      "37\n",
      "0.03480824257465119\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1456.1746258366773\n",
      "testing ber:  0.08223684210526316\n",
      "38\n",
      "0.034648657340477125\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1454.3779676321299\n",
      "testing ber:  0.08223684210526316\n",
      "39\n",
      "0.03466956228255592\n",
      "testing MSE:  tensor(0.0015, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1481.654751682991\n",
      "testing ber:  0.08333333333333333\n",
      "40\n",
      "0.0345801697013543\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1442.1942600371954\n",
      "testing ber:  0.08278508771929824\n",
      "41\n",
      "0.034653318114578724\n",
      "testing MSE:  tensor(0.0014, dtype=torch.float64)\n",
      "testing MSE 0:  tensor(0.0013, dtype=torch.float64)\n",
      "testing MSE 1:  tensor(0.0015, dtype=torch.float64)\n",
      "percent loss:  1436.6532821127416\n",
      "testing ber:  0.08333333333333333\n",
      "42\n",
      "0.03466360564244554\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainloader, testloader, model, DNN_model, rc, lr, nb_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(local_loss)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_loss)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_snn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_loader, net_snn, net_dnn, rc, num_frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m input1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input1)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m input2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(input2)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnet_snn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m output \u001b[38;5;241m=\u001b[39m net_dnn(output, input1, input2)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m all_output\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, spike):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m---> 37\u001b[0m         spike \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m spike\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/block/base.py:1149\u001b[0m, in \u001b[0;36mAbstractRecurrent.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     dendrite \u001b[38;5;241m=\u001b[39m z[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, time:time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1148\u001b[0m     feedback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_synapse(spike\u001b[38;5;241m.\u001b[39mreshape(dendrite\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m-> 1149\u001b[0m     spike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdendrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, time:time \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m spike\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike_state \u001b[38;5;241m=\u001b[39m spike\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mreshape(z\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:433\u001b[0m, in \u001b[0;36mNeuron.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124;03m\"\"\"Computes the full response of the neuron instance to an input.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m    The input shape must match with the neuron shape. For the first time,\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    the neuron shape is determined from the input automatically.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     _, voltage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspike(voltage)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/cuba.py:351\u001b[0m, in \u001b[0;36mNeuron.dynamics\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamp()\n\u001b[0;32m--> 351\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[43mleaky_integrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_decay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(current)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:93\u001b[0m, in \u001b[0;36mdynamics\u001b[0;34m(input, decay, state, w_scale, threshold, debug)\u001b[0m\n\u001b[1;32m     90\u001b[0m     state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_LIDynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     output \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mdynamics(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mcontiguous(), decay\u001b[38;5;241m.\u001b[39mcontiguous(), state\u001b[38;5;241m.\u001b[39mcontiguous(),\n\u001b[1;32m     97\u001b[0m         threshold, w_scale\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:129\u001b[0m, in \u001b[0;36m_LIDynamics.forward\u001b[0;34m(ctx, input, decay, state, threshold, w_scale)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_li_dynamics_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _LIDynamics\u001b[38;5;241m.\u001b[39mDEBUG \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         _output, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m Accelerated\u001b[38;5;241m.\u001b[39mleaky_integrator\u001b[38;5;241m.\u001b[39mfwd(\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28minput\u001b[39m, decay, state, threshold, w_scale\n\u001b[1;32m    137\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/neuron/dynamics/leaky_integrator.py:215\u001b[0m, in \u001b[0;36m_li_dynamics_fwd\u001b[0;34m(input, decay, state, threshold, w_scale, dtype)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\" \"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m output_old \u001b[38;5;241m=\u001b[39m (state \u001b[38;5;241m*\u001b[39m w_scale)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(dtype)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 215\u001b[0m decay_int \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m threshold \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m w_scale\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/torch/_tensor.py:28\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, test_loader, net_snn, net_dnn, rc, lr=1e-3, nb_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac761138-0e7d-42b0-a0ed-c75ab87036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_219/3403701246.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_219/3403701246.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_219/3403701246.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_219/3403701246.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MSE RC:  tensor(0.0051, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0036, dtype=torch.float64)\n",
      "train MSE GT:  tensor(0.0033, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "RC_train_time = np.load(\"gt_train_pred.npy\")\n",
    "print(\"train MSE: \", torch.nn.MSELoss()(torch.tensor(RC_train_time), torch.tensor(train_label)))\n",
    "def test_train_both(train_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in train_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    print(\"train MSE RC: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(RC_train_time)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(all_output), torch.tensor(train_label)))\n",
    "    print(\"train MSE GT: \", torch.nn.MSELoss()(torch.tensor(train_label), torch.tensor(RC_train_time)))\n",
    "\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_train_both(train_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808d7c6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet_snn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./net_snn12.net\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(net_dnn\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./net_dnn.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mNetwork.export_hdf5\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     45\u001b[0m layer \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mcreate_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_group\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/lava/lib/dl/slayer/block/base.py:545\u001b[0m, in \u001b[0;36mAbstractDense.export_hdf5\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# dense descriptors\u001b[39;00m\n\u001b[1;32m    542\u001b[0m handle\u001b[38;5;241m.\u001b[39mcreate_dataset(\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m1\u001b[39m, ), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS10\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    544\u001b[0m )\n\u001b[0;32m--> 545\u001b[0m \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m handle\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapse\u001b[38;5;241m.\u001b[39min_channels)\n\u001b[1;32m    547\u001b[0m handle\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapse\u001b[38;5;241m.\u001b[39mout_channels)\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/h5py/_hl/group.py:161\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    158\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 161\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/.conda/envs/d2l/lib/python3.8/site-packages/h5py/_hl/dataset.py:88\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m---> 88\u001b[0m     tid \u001b[38;5;241m=\u001b[39m \u001b[43mh5t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Legacy\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[38;5;129;01mand\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/h5t.pyx:1663\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1687\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1747\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "net_snn.export_hdf5('./net_snn12.net')\n",
    "torch.save(net_dnn.state_dict(), './net_dnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "898cb37e-9af7-45f8-a3e2-8ddbd0db0dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/229205384.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/229205384.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/229205384.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/229205384.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7521, 2]) torch.Size([7521, 2])\n",
      "all_loss:  tensor(0.0024)\n",
      "no first 330 loss:  tensor(0.0014)\n"
     ]
    }
   ],
   "source": [
    "temp_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test_MSE(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "    \n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "        labels.append(target.cpu().detach().numpy())\n",
    "    \n",
    "    all_output = torch.tensor(np.concatenate(all_output, axis=0)).detach()\n",
    "    labels = torch.tensor(np.concatenate(labels, axis=0)).detach()\n",
    "    print(all_output.shape, labels.shape)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    print(\"all_loss: \", loss_fn(all_output, labels))\n",
    "    print(\"no first 330 loss: \", loss_fn(all_output[330:, :], labels[330:, :]))\n",
    "\n",
    "test_MSE(temp_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7acff8c-50b2-4bd2-93f8-b3106dddedbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98/3202473027.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(target).float()\n",
      "/tmp/ipykernel_98/3202473027.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(input).float()\n",
      "/tmp/ipykernel_98/3202473027.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input1 = torch.tensor(input1).float()\n",
      "/tmp/ipykernel_98/3202473027.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input2 = torch.tensor(input2).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18902153558052434\n"
     ]
    }
   ],
   "source": [
    "all_output = []\n",
    "inputs = []\n",
    "labels = []\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "def test(test_loader, net_snn, net_dnn):\n",
    "    all_output = []\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for input, input1, input2, target in test_loader:\n",
    "        inputs.append(input)\n",
    "        labels.append(target)\n",
    "        target = torch.tensor(target).float()\n",
    "        input = torch.tensor(input).float()\n",
    "        input1 = torch.tensor(input1).float()\n",
    "        input2 = torch.tensor(input2).float()\n",
    "    \n",
    "        output = net_snn(input)\n",
    "        output = net_dnn(output, input1, input2).cpu().detach().numpy()\n",
    "        all_output.append(output)\n",
    "    \n",
    "    all_output = np.concatenate(all_output, axis=0)\n",
    "    ber = rc.my_test(all_output)\n",
    "    print(ber)\n",
    "    \n",
    "test(test_loader, net_snn, net_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ee219a-952a-4395-b2a9-db85d18f17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        ...,\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "A1 = 8 * torch.ones((128, 8))\n",
    "A2 = torch.ones((128, 1))\n",
    "print(A1 + A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eebf40-ab07-4dda-9afb-3caa814cefa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l:Python",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
